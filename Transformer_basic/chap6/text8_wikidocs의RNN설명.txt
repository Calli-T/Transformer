https://wikidocs.net/22886
https://byumm315.tistory.com/entry/RNN%EC%9D%84-%EC%95%8C%EC%95%84%EB%B4%85%EC%8B%9C%EB%8B%A4

메모리 셀은 그 자체로 뉴런 or 퍼셉트론이다

스팸 메일 분류는 다대일이다. 시퀀스가 여럿이고, 결과는 하나

은닉층 h_t = tanh(W_x * x_t + W_h * h_t-1 + b)
출력값 y_t = f(W_y * h_t + b)

메모리 셀(= 은닉층의 퍼셉트론)은 활성화 함수로 하이퍼볼릭 탄젠트를 많이쓴다
f는 활성화 함수로, 문제의 종류에 따라 다름

은닉층의 갱신은 이전 은닉 상태값과 입력값 각각에 가중치가 들어간걸 활성화함수에 거르고 뽑는다
출력값은 입력이 직접 들어가진않고, 현재 은닉 상태에만 가중치가 곱해져서(입력이 다시 들어가지는 않음) 활성화 함수에 넣는다

임베딩 벡터의 차원이 d라면, 은닉 상태(= 은닉층의 퍼셉트론 개수)가 D_h일 때
벡터/행렬 길이는 다음과 같다

x_t(입력): d * 1 / 임베딩 크기 d
W_x(입력 상태에 대한 가중치): D_h * d / 임베딩 크기 d에서 -> 은닉층 크기 D_h
W_h(이전 상태에 대한 가중치): D_h * D_h / 은닉층 크기 D_h -> 은닉층 크기 D_h
※   자기 자신에게만 가는게 아니더라
    한 메모리 셀이 과거 시점에서
    은닉 상태를 입력 받을 때
    은닉층의 모든 메모리 셀에서 받아오는 구조
h_t-1(각 메모리 셀의 이전 은닉 상태): D_h * 1 / 은닉층 크기 D_h와 같음
b(편향의 크기): D_h * 1 / 메모리 셀 하나에 하나씩, 은닉층의D_h와 같음,
※ 위키말고 책의 표기는 은닉과 출력의 편향이 다르게 표기되어있음
※ 해당 은닉층에서 출력층이 따로 없는경우, 편향이 따로 더 없는듯, y_t를 만들어내는 편향이..., 이건 설명서마다 기본값이 조금씩 다르다

입력층의 크기가 100(임베딩 벡터의 차원) d = 100
은닉층의 메모리 셀이 128개
D_h = 128
w_t = 100

임베딩층은 5000행(단어수), 100열(특징의 크기)
W_x = 128 * 100
W_h = 128 * 128
h_t = 128
b(hidden) = 128
b(output) = 1

529441개의 은닉층

양방향의경우, 한 은닉 층에서 메모리 셀이 2배로 늘어나는듯

313p의 경우,
한번에 처리하는 수(= 배치 크기)도 고려해서 초기 은닉 상태 크기를 정하고 있다.
배치*시퀀스*특징개수의 순서가 입력 크기(차원)
출력은 배치, 시퀀스, (양방향여부 + 1) * 은닉 상태 크기이다 [4, 6, 512]
저 모델은 은닉층에서 다음 층으로 안넘어가고 그대로 출력해버리는듯
은닉 층은 각 층에 (은닉 크기)*(양방향여부+1)만큼 있다
이유는 잘모르지만 표기순서가
[레이어개수*(양방향여부+1), 배치개수, 층당 은닉상태개수]
[6, 4, 256]

...RNN파트는 너무 어려우니 다시 읽어보자