355p
트랜스포머는 모델은 입력 시퀀스를 병렬로 처리하는 기능을 가진다
셀프 어텐션을 기반으로 하며, 이는 순차 처리나 반복 연결에 의존하지 않고
입력 토큰 간의 관계를 직접 처리하고 이해하도록한다.
모델이 재귀나 합성곱 연산 없이 입력 토큰 간의 관계를 직접 모델링한다.

대규모 데이터셋에 효율적이라고 한다
언어 모델링과 텍스트 분류에 효과적
기계 번역, 언어 모델링, 텍스트 요약과 같은
장기적인 종속성을 포함하는 작업에 주로 사용

356p
트랜스포머 기반 모델의 학습 방식은 2개가 있다.

오토인코딩방식: 랜덤하게 문장의 일부를 빈칸 토큰으로 만들고
해당 빈칸에 어떤 단어가 적절할지 예측하는 작업(Task) 수행
예측할 때 양옆의 토큰을 참조하므로 양방향구조, 이를 인코더라고 한다

자기 회귀 방식: 예측되는 토큰의 왼쪽에 있는 토큰들만 참조
단방향이고 이를 디코더라고한다

357p
※ 트랜스포머 해석
https://analytics4everything.tistory.com/150

트랜스포머는 위치 임베딩, 순방향 신경망, 멀티헤드 어텐션으로 이루어져있다.

{
트랜스포머 모델은 어텐션 메커니즘을 사용하며
이를 이용해서 시퀀스 임베딩을 표현한다.

인코더와 디코더 간의 상호작용으로
입력 시퀀스의 중요한 부분에 초점을 맞추어 문백을 이해하고
적절한 출력을 생성한다.
}

인코더는 입력 시퀀스를 임베딩하여 고차원 벡터로 변환
디코더는 인코더의 출력을 입력으로 받아 출력 시퀀스를 생성
이 때, 어텐션 메커니즘은 인코더와 디코더 단어 사이의 상관관계를 계산하여 중요한 정보에 집중
입력 시퀀스의 각 단어가 출력 시퀀스의 어떤 단어와 관련이 있는지를 파악,
번역이나 요약문 생성등의 작업 수행

358p
인코더와 디코더는 두 부분으로 되어있고
이는 각각 N개의 트랜스포머 블록으로 되어있다.
이 블록은 멀티 헤드 어텐션과, 순방향 신경망으로 이루어져있다

멀티헤드 어텐션은 여러 어텐션을 병렬 처리한다.
입력 시퀀스에서 쿼리, 키, 값 벡터를 정의하고
입력 시퀀스들의 관계를 셀프 어텐션 한다.
쿼리와 키의 유사도를 계산하고,
해당 유사도를 가중치로 사용하여 값 벡터를 합산한다.

이렇게 만든 어텐션 행렬은 입력 시퀀스의
각 단어의 임베딩을 대체한다.

---
순방향 신경망은 이과정에서 산출된 임베딩 벡터를
더욱 고도화 하기 위해 사용된다.
여러 선형 계층으로 되어 잘아는 신경망의 구조처럼
입력 벡터에 가중치를 곱하고 편향을 더한것을 활성화함수에 넣는다
학습된 가중치들은 입력 시퀀스 각 단어의
의미를 잘 파악할 수 있는 방식으로 갱신된다.

---
트랜스포머는 인코더와 디코더로 이루어져있으며
각각 N개의 트랜스포머 블록으로 이루어져있고
블록은 멀티헤드어텐션과 순방향 신경망으로 되어있다
멀티헤드 어텐션에서 단어의 임베딩을 대체할 어텐션행렬을 제작하고
순방향 신경망에 넣어 각 단어의 의미를 잘 파악할 수 있도록 가중치를 갱신한다.

---
359p
트랜스포머는 입력 시퀀스를 소스와 타켓으로 나누어 처리한다.
인코더는 소스 시퀀스를 위치 인코딩된 입력 임베딩으로 표현해
트랜스포머 블록의 출력 벡터를 생성한다
이 출력 벡터는 입력 시퀀스 데이터의 관계를 잘표현한다

디코더도 인코더와 유사하게 트랜스포머 블록으로 구성되어 있지만
마스크 멀티 헤드 어텐션을 사용해
타깃 시퀀스 데이터를 순차적으로 생성시킨다
이 때, 디코더 입력 시퀀스들의 관계를 고도화하기 위해
인코더의 출력 벡터 정보를 참조한다. <- ??? 이게 무슨 소리고

최종적으로 생성된 디코더의 출력 벡터는 선형 임베딩으로
재표현되어 이미지나 자연어 모델에 활용된다
---
입력 임베딩과 위치 인코딩

트랜스포머는 RNN과 달리 입력시퀀스가 병렬 처리되므로
단어의 순서 정보를 제공하지 않기 때문에
위치 정보를 임베딩 벡터에 추가할 필요가 있다.
이를 위해 위치 인코딩 방식을 트랜스포머에서 사용한다

위치 인코딩은 입력 시퀀스의 순서 정보를 모델에 전달하는 방법으로
각 단어의 위치 정보를 나타내는 벡터를 더하여 임베딩 벡터에 위치 정보를 반영
결합된 최종 입력 벡터를 학습한다.

위치인코딩에서는 각 토큰의 위치를 각도로 표현해
sin과 cos함수로 위치 인코딩 벡터를 계산한다
토큰의 위치마다 동일한 임베딩 벡터를 사용하지 않기 때문에
각 토큰의 위치 정보를 모델이 학습할 수 있다 ???
(위치 정보를 도출하는 과정은 https://hongl.tistory.com/231)

361p
해당 페이지의 PositionalEncoding class는
파이토치로 작성된 위치 인코딩 코드의 예시이다.

위치 인코딩의 수식 PE는 다음과 같다
PE(pos, 2i) = sin(pos/10000^(2i/d_model))
PE(pos, 2i + 1) = cos(pos/10000^(2i/d_model))

pos: 입력 시퀀스에서 단어의 위치
i: 임베딩 벡터의 차원에서의 인덱스(※ 정확히는 2i또는 2i+1의 꼴). 즉 하나의 위치 임베딩 벡터를 위해 i=0부터 i=(d-1)까지 모든 차원의 값을 계산
d_model: 트랜스포머 모든 층에서 출력이 같다고 하며 그 값을 나타내는 상순. 이 값은 임베딩 벡터의 차원이기도 함

※ d값은 책에서는 입력 임베딩의 차원 128을 사용, 근본 논문에서는 51를 사용

해당 코드의 출력 텐서 차원은 [최대 시퀀스 길이, 1, 입력 임베딩의 차원]이다.