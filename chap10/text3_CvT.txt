644p
ViT의 물체 크기나 해상도를 계층적 학습하기 어려움 - 모든 패치를 동일한 크기
CvT는 CNN에서 쓰는 계층 구조를 ViT를 적용해서
크기별 지역 특징/전역특징을 모두 활용하여 이를 타개
-> 적은 매개변수로 높은 성능

(ImageNet Bench기준 그렇게 높지는 않던데,
후속모델에서 CvT를 계승한게 이름이 달라졌다던지 일반 CNN->ResNet 마냥
Swin등 다른 ViT기반모델에 밀린건지
ViT등에 데이터셋을 아주 많이 때려박으면 개선이되는건지
아니면 이 모든게 합쳐졌던지 확인해봐야함)

645p
저수준에서 선, 점, 중간에선 눈귀, 고수준에선 얼굴 구조의 특징을 잡는등 CvT의 계층구조 예시
CvT에서 어텐션 레이어에 넣기전에 Conv에 먼저넣음,
Output Feature Map을 패치로 잘라 '겹쳐' 어텐션시킨다

646p
ViT에서는 위치 임베딩을 사용하나,
CvT는 Conv과정에서 커널을 이전과 조금씩 겹쳐 이동하므로 위치정보가 따로 필요없는듯하다

ViT에서 순서 (패치 임베딩(겹치지 않게 stride) -> 선형 변환(=필터와 합성곱)으로 선형 임베딩) -> 위치임베딩을 더함
CvT의 순서는 합성곱 임베딩(겹치게 stride) -> 합성곱 임베딩

사실 ViT도 안겹치게 Stride해서 Conv layer쓰는걸로 자르기/선형변환 둘 다 하기때문에 별 차이는 없고 stride 차이인듯

괜히 헷갈리게 적어놨어 책은...
stride로 안겹치게 한다음 위치임베딩을 나중에 더하기
vs stride 겹치게 feature map 뽑고 위치임베딩 안쓰기

647p
CvT 임베딩 방식의 예시, kernel 크기 3, stride 1로 합성곱하는 모습
커널(혹은 그게 모인 필터) 각각과 합성곱한 결과를 Flatten한것을
그대로 선형 임베딩 이후의 QKV로 쓰는모양?

648p
어텐션에 대한 합성곱 임베딩이란? 2D로 재구성된 토큰맵에서
분리 가능한 합성곱 연산을 적용해 성능 저하 및 계산 복잡도를 낮추는 연산
??? ???
QKV에서 Q와 KV에서, stride를 다르게 하여 패치 길이를 각각 9와 4로 다르게 하는 예시를 보여준다
https://velog.io/@kiolke/CvT-Introducing-Convolutions-to-Vision-Transformers-%EC%A0%9C5%EB%B6%80
여긴 Q/KV가 16/4

Q/KV의 길이가 다르더라도 (K와 V는 같아야함) 어텐션의 입출력 길이는 같게되는 이유는
Q*transpose(K)*V에서
임베딩을 거친이후 Q가 a*1/KV가 b*1일 때,
Q*transpose(K)는 a*b크기 벡터, 이를 다시 V와 곱하면 a*b * b*1이므로 a*1의크기 즉 원래 벡터길이다
이게 맵, 스코어, 등등 어텐션의 어떤 요소와 엮여있는지부터 다시 시작