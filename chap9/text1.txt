505p
객체 탐지: 이미지나 영상에서 특정 객체를 탐지하고 영역을 인식하는 CV 기술
분류: 8장에서 늘 하던거
지역화: 이미지에서 물체의 위치를 파악하는 작업
경계 상자: 객체 영역을 사각형 형태로 표현
마스크: 객체 영역을 픽셀 단위로 정확히 분할해 표현하는 기술, 객체 영역의 정확한 표현을 위해 사용

객체 탐지는 분류랑 지역화를 동시에 함

506p
객체 탐지의 방법으로는 경계 상자 탐지, 의미론적 분할, 객체 분할이 있다고함

경계 상자 탐지는 경계 상자를 활용해 객체의 영역을 간단하게 표현
하지만 Rectangle로 표현해서 상세한 영역을 파악하긴 어려움

의미론적 분할은 마스크를사용해서 이미지와 객체의 배경을 픽셀 단위로 분할
영역을 정확히 분할해서 상세한 모양 확인 가능, 배경과 같이 광범위한 영역도 가능
픽셀 단위로 분류하기 때문에 계산 비용이 높고 객체간 경계에서 오분류할 가능성이 있음

객체 분할은 이미지에서 객체를 픽셀 단위로 분리하고
경계 상자와 클래스 레이블을 추출
경계 상자 탐지와 의미론적 분할의 기능을 모두 갖고 있기 때문에 좀 더 정확한 객체 인식 가능
둘다씀->더 높은 계산비용과 더 많은 데이터 요구

507p
발전순서는
R-CNN -> Fast R-CNN -> Faster R-CNN

※ R-CNN: 영역 제안, 특징 추출, 서포트 벡터 머신을 활용한 객체 탐지 수행용 딥러닝 모델
{
R-CNN의 영역 제안은 선택적 탐색(Selective Search)
알고리즘을 사용해 영역을 추출하고 객체를 탐지한다

선택적 탐색 알고리즘은 규칙 기반의 알고리즘으로
입력 이미지에서 객체가 있을 만한 후보 영역을 생성한다.
1. 후보영역을 생성할 때 입력 이미지의 인접 픽셀과 비슷한 [색상, 질감, 밝기, 크기] 등
유사한 특징을 갖는 영역을 군집화한다.
2. 군집화된 영역에도 같은 과정을 반복해 군집을 확장해간다.
3. 이를 통해 얻은 군집으로객체가 존재할 수 잇는 영역을 추출한다.

1. 선택적 탐색 알고리즘으로 2000여 개의 영역이 생성
2. 영역마다 AlexNet을 적용해 4096 size vector를 추출
3. Vector들을 SVM에 넣고 객체 분류를 진행하여 클래스와 확률값을 각 영역에 대해 출력
4. 겹치는 영역을 비최댓값 억제(Non-Maximum Suppression, NMS)를 수행하여 가장 우수한 영역만 남김
5. 대략적인 영역만 남은 후보 영역에 박스 회귀(Box Regression)을 진행하여 실제 영역과 일치하게 학습하여 위치와 크기를 조절
}
기존 객체 탐지와의 R-CNN의 차이점: 영역별로 나눠 객체 여부를 판단vs객체가 위치할만한 후보를 생성

509p
R-CNN 단점
1. 2000여개 영역에 다 CNN을 박아서 너무 느리고 비쌈
2. Region Suggestion/CNN/SVM을 사용하므로 모델 학습 단계가 분리되어
종단 간 학습이 불가능하고 성능 향상에 무리가 있음
※ 종단 간 학습(End-to-End Learning): 입력에서 출력까지 모든 과정을 하나의 모델로 학습

???(2번 분리 문제는 CNN도 쓰고 박스도 학습하고 그래서 그런가?)

1. Fast R-CNN은 입력 이미지를 사전 학습된 합성곱 신경망에 전달해 특징맵을 추출
2. 이 특징 맵에 영역 제안 방법으로 관심 영역(Rogion of Interest, ROI)을 찾는다
3. 관심 영역 풀링(ROI Pooling)을 사용해 고정된 크기의 특징 맵을 얻는다
4. 해당 특징 맵을 FC layer에 전달해 물체의 클래스와 위치를 예측한다.

관심 영역 풀링이란? 관심 영역을 잘라내 고정된 크기의 특징 맵으로 변환하는 작업
다양한 크기의 후보 영역을
합성곱 모델의 입력값으로 전달하기 위해선
고정된 크기의 특징 맵으로 변환할 필요가 있음
1. 관심 영역을 특징 맵 크기에 맞게 나누고
2. max pooling 적용해 고정된 특징 맵 크기로 적용(이를 모든 관심 영역에 적용)
3. 둘로 나눠 하나는 소프트맥스로 클래스 분류
4. 다른 하나는 박스 회귀를 통해 경계 상자를 검출

특징 추출->관심 영역 풀링->객체 분류/박스 회귀

https://ganghee-lee.tistory.com/36
-> 책의 설명은 뭔가 잘 안와닫는데?

홈페이지의 설명
1. (R-CNN과 동일하게) Selective Search를 통해 RoI를 찾는다
2. 전체 이미지를 CNN에 통과시켜 feature map을 추출
3. 찾은 RoI를 feature map 크기에 맞춰서 투사(projection) (feature map에서 RoI의 지분만큼 자르는듯)
4. 투사한 RoI에 RoI풀링 진행
5. 풀링 이후 FC layer를 통과해 feature vector추출
6. 두 분기로 나눠 하나는 softmax로 분류작업실시
7. 다른 한 분귀는 학스 회귀로 박스 크기 조정
※ (feature vector를 다시 FC layer에 넣어서 진행하는게 해당 페이지의 그림에 존재함)

홈페이지의 RoI Pooling설명
feature map을 projection하고나면 각기 다른 크기의 feature map을
pooling해서 고정 크기의 feature map으로(그리고 이걸로 만드는 feature vector로) 만든다

h*w 크기의 feature map이 있고 원하는 고정 크기가 H*W라면
나눠진 한 구역이 (h/H) * (w/W)인 Grid를 원래의 feature map에 올려
한 구역에서 가장 큰 값을 뽑아내는 max pooling을 통해
H*W크기의 고정 feature map(vector)를 뽑아내고 이걸 FC에 집어넣는 모양이다(Flatten해야겠지???)