DDPM 구현 요약
dataloader는 데이터셋을 데이터로더로 만드는 함수가 들어있다
평균와 표준편차는 나중에 비정규화 과정에 그림에 곱해주려고 존재한다
채널, 높이, 넓이 3축으로 존재함, 각각 나눠서 평균과 표준편차를 구한것

UNet은 이미지의 어떤 잡음이 있는지 잡음을 예측하는데 쓴다

잡음의 분산(※1어디서 가져오는지는 후술)과 잡음 낀 이미지(레이어 정규화된것)를 입력받는다
분산쪽은 사인파 임베딩(※2), 업샘플링을 거쳐 (c/2, h, w) 크기의 텐서로 변환
잡음 이미지는 합성곱으로 (c/2, h, w) 크기의 텐서로 변환
이 둘을 concat하여 (c, h, w)텐서로 만들고 이를 블럭의 시작 입력으로 사용한다

블럭은 여러 layer로 되어있으며, 이 블럭들을 거쳐 (c, h, w)크기의 잡음을 예측한다
blocks의 residual, up, down block은 이를 위해 만들어졌으며, 잔차 연결을 사용한다
down블럭에서 feature map 크기를 줄이고 upblock에서 늘리는데,
이 과정에서 down블럭의 출력을 블럭이나 레이어를 건너뛰고 이전층의 출려과 concat하여 사용한다.

그러나, 많은 unet이 합성곱보단 ViT를 사용한다

ddpm은 unet을 학습시키고, 학습한 unet을 통해 무작위 잡음을 넣어 이미지를 생성할 수 있다.
학습 과정에서는 데이터셋의 이미지에 노이즈(※3)를 씌우고(※4)
이를 unet으로 예측한다음(※1) 실제 값과 비교하여
이를 손실함수에 넣고 역전파하는것으로 이루어진다.

학습한 unet은 즉시 사용되는것이 아닌
ema신경망에 카피하는 과정을 거치고
생성도 ema 신경망에서한다.
그러나 이는 필수적인 과정은 아니다

실제 이미지의 생성에는 임의로 설정한 확산 단계와 무작위 잡음을 가지고 이루어진다
완전한 무작위 생성에는 (※4) 표준 정규 분포를 따르는 무작위 잡음을 생성하는것으로 시작한다
잡음의 분산은 확상 과정 생성 함수에 넣어 (※1) 가져온다
임의로 정한 단계수만큼 역방향 확산 과정을 거쳐 이미지를 만들어낸다.

※1-1 unet은 잡음을 예측하는데 잡음의 분산과 잡음낀 이미지를 필요로한다.
정규 분포의 가법성을 따르게하는 확산 과정 생성 함수에 무작위 확산 시간을 넣어
잡음의 분산/신호의 표준편차를 가져온다 이를 제곱한것이 잡음의 분산이다
잡음의 분산은 정방향 확산 과정의 특성상 사용되는 잡음비 그 자체이기도 하다.
※1-2 역방향 확산 과정은 최종 확산 단계 t를 1로 고정하고
그 사이를 임의로 정한 단계수만큼 나눠서 [0, 1) 사이의 값을 단계수만큼 뽑아낸다
각 역방향 확산 과정에서, 잡음의 분산 곧 잡음비는 해당 단계의 단계수를 1-1과 동일한 함수에 넣어 가져온다
덤으로, 잡음낀 이미지는 자체는 원본이미지/무작위잡음/신호비/잡음비 4가지가 모두 있으니 텐서곱으로 나온다.
※2 잡음의 분산을 선형 변환하여 임베딩으로 전환, 트랜스포머 위치 임베딩과 근간이 같은 기술임
※3 잡음은 표준 정규 분포에서 무작위로 뽑아낸다
※4 stable diffusion의 키워드 생성은 다를 수도 있다???