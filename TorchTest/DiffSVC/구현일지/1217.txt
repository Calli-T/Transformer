----- 짚고 넘어갈 사실들 -----

1. hubert, f0, mel2ph가 조건으로 사용됨
2.wavenet은 그럼 뭘 학습하는가?
(gemini 피셜)
 - 음소, 음절, 단어 단위의 발음 특징
 - 음성 신호의 시간적 패턴???
 - 음높이, 음색, 강세
 - 억양
 - 그 외 잡음 적응
(gpt 피셜)
억양은 음압변화와 주파수 변화를 모두 아우르는 개념이며
wavenet은 음소를 어떤 음압으로 바꿀 건지 결정할 수 있다.
이 때, wavenet은 sequence 모델이므로 음소간 시간적 관계를 학습하여
음소를 어떤 음압으로 바꿀지 결정하는 것 뿐만 아니라,
음소간의 전환에서 자연스럽게하는 음압 변화를 결정할 수 있다


----- 점검 -----

덜 만든 기능들
1. training
2. (학습, 추론 상관없이) 디렉터리 내부의 모든 음원을 wav로 (추가로 sampling rate 변경)
3. wav를 잘라서 배열로 만들어 사용하기 (추가로 VRAM 크기에 따른 옵션)
4. 샘플링 (가속) 기법
5. argparser(최소한 모델/학습재료/추론재료/결과물 디렉토리라도 선택할 수 있도록)
6. wav말고 flac등 다른 확장자로 생성

다듬어야할 부분들
1. spec_min, spec_max을 cpop이 아닌 다른 데이터셋의 것으로 변경
2.

확장 기능 추가
1. 가사만 변형
2. 그럴듯한 UI 제작 - electron
3. Window에서 동작하는 설치패키지
4. 테스트 배포용 AMD
5. vocoder 다른거 사용
6. wavenet 대신 딴거 사용? transformer 기반 모델이라던가

탐구 대상
1. wavenet의 구조
2. vocoder의 구조
3. hubert의 세부 구조 - 클러스터링 위주로
4. diffusion에서의, condition embedding(cfg와 별개로 학습할 것)
5. diffusion 샘플링 (가속) 기법 이론 배우기, PNDM부터 시작
6. crepe의 원리