칸-바야시의 구현은 다 좋은데 import해도 코드로 쓰는게 아니고, 쉘 스크립트를 조작하여 사용하는 것이다
이를 위해 명령어를 파싱하는 구조까지 존재한다.
제법 복잡하고 여러 상황에 대응하기 때문에, 다른 방법을 찾아보거나 코드를 자세히 보자

라이브러리의 코드를 뜯어보면 parse 아래에 사용법이 있으니,
거기에는 모델, 런치, 디코드, 파싱 등등의 코드가 있다.
이부분만 적절히 뜯어 가져가면 사용에 문제는 없을것이다.

가지치기가 끝난 코드에 대해서는
실행 부분에서 어디가 뭐하는 코드인지는 잠깐 보도록하자
목표는 wav->mel->wav이며, wav는 뭘로 mel로 바꾸는지도 알아봐야한다

할일
1) Analysis-synthesis 예제 깃허브에 나와있는대로 사용
2) 코드 가지치기해서 디렉터리에 담고, 모델과 같이 두기
3) 그 과정에서 멜 스펙트로그램 변환 방법과 형식 찾기 밑 호환성 분석
4) 추후 pwg 학습을 위해 코드의 실행 흐름을 따라 간단히 주석
5) 쉘 스크립트를 인식하는 코드를, 함수화 하여 원하는 대로 '파이썬코드 상에서' 사용가능하도록 개조


{
1)의 과정은
    음원파일 가져오기 ->
    wav로 변형(sample rate를 일단 맞추긴했으나 필수인지는 모르겠음, 모노채널로 변경 필수) ->
    모델 가져오기 -> process->normalize->decode
    하는 방법은 ana-syn1.txt에, 파형보기는 show_wave2.py에 적어놓음

    파형 시각화 방법 참고자료
    https://dacon.io/competitions/official/235616/codeshare/1277
    그 외 음원 가져오는건 Toyproject_AI어쩌고 북마크 디렉터리에 넣어둠

    사용한 모델은
    vctk_parallel_wavegan.v1
    kss_parallel_wavegan.v1

    kss구린데 문장 수가 달라서 그런듯
    VCTK는 44000문장, kss어쩌고는 770문장이고 둘다 학습은 400,000번함
    VCTK 롱버전은 1,000,000번 학습 했는데 좀 낫더라
}

{
2)의 과정에서
일단 멜스펙트로그램을 뽑아낸다음 거기서 소리를 만들어내는것은 맞는것같다. 코드를 더 자세히 살펴볼 필요가 있다.
특히 f0는 대체 뭐에다 쓰는지원

패키지의 bin 디렉터리의 코드에서 decode, normalize, preprocess만 딱 쓰려고 가져왔고,


아직 안한것들, 해야한다.
하위 패키지로 있는 코드들이 있기때문에 코드 가져오고, import 정리 해줘야한다
그리고 argparser로 파싱한 것들 대시('-')가 언더스코어('_')로 바뀐채로 들어가있으니 조심
필요 없는 코드는 모조리 날리자

나중에 코드 쓰고, 학습하고, 이런 것들은 저걸로 해도 되고 딴데서 코드 긁어와도 상관 없을듯
}