완전 오리지널 DDPM 코드에서 p_sample은 문자 그대로
평균 + 잡음 * 분산이다

ddpm 논문에서 algorithm2에 나와있는 sample 과정에서,
앞쪽에 1/sqrt(alpha_t)붙은 항은
x_t에 붙은 잡음이 제거된 pred_xstart이다.

뒤의 시그마는 노이즈의 분산이며, 이를 잡음에 곱하여 더하는 것으로 x_t-1를 샘플링했던 것이다.

IDDPM의 코드에서는 q_mean_posteriror_variance등 이것저것을 사용하여
q(x_t-1|x_t, x_0)를 구현해둔것 같다.

요약하자면, 단순히 p_sample 하는것은 그저 x_t를 생성하는 과정이며
우리는 x_t-1를 생성하기 위해 이 값을 변형하여 사용하여야 한다

문제들
1.
sqrt_alpha_t
alpha_cumprod_t 등 schedule 관련 값들은 tensor를 썼다가는 형식이 맞지 않아 곱해지지를 않는다.
numpy 값으로 대체하자

2. VRAM이 폭발한다.
with torch.no_grad():와 model의 .eval()을 잊지말자
그래도 안되면 batch를 줄이던지, 아무리 줄여도 안되면
기기 한계 일듯 ㅋㅋㅋㅋㅋ

3. x_t에서 x_0로 갈 수록 값이 0에 가까워 지다가 결국 nan이 되어버린다.
드디어 원인을 찾았다!!!!!!!!
alpha_cumprod는 무한정 소수를 곱해버리니 끝에 가면 0이 되어버렸던것
GPT의 말대로 log의 힘을 빌어보자
torch.log(alpha_t_cumprod)