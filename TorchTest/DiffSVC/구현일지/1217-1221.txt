----- 짚고 넘어갈 사실들 -----

1. hubert, f0, mel2ph가 조건으로 사용됨
2.wavenet은 그럼 뭘 학습하는가?
(gemini 피셜)
 - 음소, 음절, 단어 단위의 발음 특징
 - 음성 신호의 시간적 패턴???
 - 음높이, 음색, 강세
 - 억양
 - 그 외 잡음 적응
(gpt 피셜)
억양은 음압변화와 주파수 변화를 모두 아우르는 개념이며
wavenet은 음소를 어떤 음압으로 바꿀 건지 결정할 수 있다.
이 때, wavenet은 sequence 모델이므로 음소간 시간적 관계를 학습하여
음소를 어떤 음압으로 바꿀지 결정하는 것 뿐만 아니라,
음소간의 전환에서 자연스럽게하는 음압 변화를 결정할 수 있다


----- 점검 -----

덜 만든 기능들
1. training
2. (학습, 추론 상관없이) 디렉터리 내부의 모든 음원을 wav로 (추가로 sampling rate 변경)
3. wav를 잘라서 배열로 만들어 사용하기 (추가로 VRAM 크기에 따른 옵션) + 추론 결과물 다시 붙이기
4. 샘플링 (가속) 기법
5. argparser(최소한 모델/학습재료/추론재료/결과물 디렉토리라도 선택할 수 있도록)
6. wav말고 flac등 다른 확장자로 생성
7. 생성 결과물의 저장 이름 변경
8. dirname를 사용하여 자동으로 가장 높은 epoch의 모델 장착

다듬어야할 부분들
1. spec_min, spec_max을 cpop이 아닌 다른 데이터셋의 것으로 변경
2.

확장 기능 계획
1. 가사만 변형하는 모델 제작
2. 그럴듯한 UI 제작 - electron
3. Window에서 동작하는 설치패키지
4. 테스트 배포용 AMD
5. vocoder 다른거 사용
6. wavenet 대신 딴거 사용? transformer 기반 모델이라던가

탐구 대상
1. wavenet의 구조
2. vocoder의 구조
3. hubert의 세부 구조 - 클러스터링 위주로
4. diffusion에서의, condition embedding(cfg와 별개로 학습할 것)
5. diffusion 샘플링 (가속) 기법 이론 배우기, PNDM부터 시작
6. crepe의 원리

----- 1220 -----

학습기를 제작 중인데 다음과 같은 코드에서 학습 기능이 파편적으로 나눠져 있다
run.py/train_pipeline.py/base_task.py/SVC_task.py
그리고 최종적으로 학습기는 pl_utils.py에 있으며,
이건 답이없다, DDP를 비롯하여 무수한 옵션, 무수한 기능이 있으며, 나에게는 그 모든것이
'지금 당장은' 필요치 않다

training 기능을 제작하기위해 필요한 것들을
함수, hparams, class 상관없이 모조리 꼽아보자면
1. optimizer
2. loss type
3. dataloader
4. wav slicer
5. training steps
6. zerograd / backward / 등등

원본의 코드에서 training용으로 음성을 자를 때는 sep_wav.py,
이를 이진화하는 preprocessing/binarize.py
대체 왜 이진화?

와중에 놀라운 사실을 하나 발견했는데,
일단 get_raw_cond에서 가장 시간이 많이 들어가는 작업은 crepe이다
(mel2ph/mel/wav/hubert는 별로 시간이 안들어간다)
그래서인지 해시에 한 번 f0로 만든거 다시 안하는 작업을 만들어놨다


순서는 dir의 모든 wav를 44100hz/mono/wav로 제작하고 ->
파일을 쪼개서 따로 저장하며 ->
이를 wav/mel/hubert/mel2ph/f0로 바꾼다
저걸 싹 npz로 저장하면, 92초에 24.3 MiB가 들어간다
2시간짜리는 1901.7 MiB이다

잘라서 싸그리 다 램에 들고 있을 것인가?
시간이 많이 들어가는 f0만 저장해둘 것인가?
아니면 모조리 npz로 저장해둘 것인가?
일단 6분 조금 넘는 영상은 'HuBERT' 조차 넘지 못했다. 15.80 GiB이다

아무래도 전부 10~15초 사이로 쪼개고
그것들의 wav/mel/hubert/mel2ph/f0중 f0는 필수로 저장, 나머지는 넣을지말지 고민해야할듯하다
일단 training은 음원을 잘라서저장하고 잘린 음원의 f0도 저장해야한다는 것이 명확하며

infer의 경우를 예외로 둘 것인지를 생각해보아야한다

44100hz, mono, 16bit, 102초 wav는 27.9 MiB이다
들어가는 시간은 wav, mel/f0/hubert/mel2ph가 각각
0.1715초
25.3734초
0.5912초
0.0022초 이며,
f0'만'을 저장했을 경우 같은 파일에 70.5 KiB가 저장된다
... f0만 저장해야겠다

sep_wav는 '목소리 추출이 완료된 wav' 또는 '완전 무보정 상태의 mp4'만 받을 수 있다