※ nsf_hifigan은 판매금지가 있더라? 라이센스를 다시 읽어보고 대체제를 찾아보던가 하자

nsf_hifigan을 가져오는데서,
일단 hparams를 모델이 init에 가져와서 사용하는 구조로 변경하여 하였으나
static method wav2spec이 외부 데이터 hparams를 사용하는 static method였고
매개변수에 hparams를 주어 해결하려 하였으나 이번에는
상속받은 클래스 base_vocoder의 양식과 충돌하여, 부모 클래스의 매개변수를 추후 수정해야한다!?!

nsf_hifigan의 모델을 load 하는데서, generator의 load_state_dict와 충돌하는데
cp_dict['generator']와 충돌하니 원본 모델에서는 key 값이 어떤지 참고를 해볼 필요가 있다
unexpected key(s) 에러가 뜬다
해당 값을 1129_2에 저장해두었다
그리고 확인해보니 완전히 같은 값이다!!!
대체 무엇이 문제인가 확인해보니, 원본 코드에 Generator 클래스가 2번 작성되어있다
즉, 첫 번째 클래스는 씹혔다!!!

두 번째 클래스와 여기에 필드로 들어간 클래스를 사용하여 Generator 클래스의 코드를 가져왔고
이를 load하는 과정에서 SIGSEGV 오류가 떴으나
cuda로 전환하니 문제가 사라졌다
대체 왜 그런지는 모르겠으나
GPT는 다음과 같이 설명하였다
1. CUDA에서 문제가 해결된 이유는 GPU 메모리 컨텍스트와
텐서 처리 방식 덕분에 메모리 충돌 문제가 방지되었기 때문일 가능성이 높습니다.
CPU에서 동일한 오류를 방지하려면 초기화 상태를 철저히 점검하고,
weight_norm 관련된 코드를 디버깅하며, PyTorch 버전 호환성을 확인하세요.
2. weight_g와 weight_v 텐서가 GPU에 생성되었다면,
remove_weight_norm도 GPU 상에서 실행되어야 이를 제대로 참조 및 삭제할 수 있습니다.

일단 model의 load까지는 성공했으니,
이걸로 여러가지를 해보자

일단 wav2spec부터
NsfHiFiGAN/test1_nsf_hifigan 보면 wav2mel의 예제 코드가 있다 ※ wav2spec

이를 기반으로
1. pitch, f0
2. hubert
3. mel2ph
를 만들고
이걸 fs2에 넣으면 된다

일단 경로 문제를 해결해야하나, 나중에 파이프라인 통합할 때(fs2에 넣을 때!) 하기 위해
wav2spec_stand_alone에 wav2spec함수만 따로 떼어 구현해두었다
crepe는 어째 모델을 따로 입력 받지 않으며, torchcrepe를 쓴다
해당 함수는 data_gen_utils.py에 get_pitch_crepe에 있다

일단 gt_f0와 coarse_f0를 얻는데 성공했다, 근데
gt는 ground truth인데, coarse(거친)이 뭔가 알아봤더니
사람의 음을 인지하는 기준(threshold)이 있고,
이를 반영한 Melody scale로 변환하여 linear하게 다루도록 하는 방법인듯하다
f0_to_coarse가 해당 기능을 구현한 함수이다(로그 스케일도 충실하다)
중간에 f0의 배열 길이가 줄어드는 구간이 있는데, 자세한 알고리즘은 모르겠으니 추후알아보자???

그리고 중요한거 한가지!!!
crepe의 코드는 device가 cuda 고정으로 되어있다!!! - 나중에 hparams에 device항목에
영향을 받도록 합칠 때 코드를 바꿔야한다
----- 여기까지 wav, mel, f0, mel-scale-f0 생성 코드 제작 완료 -----

1. HuBERT에 관한 사실들 정리
1) Hubert는 모델 자체가 GaussianDiffusion class에 phone_encoder 입력으로 들어간다
1-1) 그런데 내부에서는 아무것도 안한다!
1-2) forward할 때 외부에서 hubert로 처리한 결과물을 받아서 처리한다
1-3) 결론: Hubert의 결과물 만이 fs2 모델에 입력으로 들어간다.
2) hubert의 입력으로는 raw waveform이 들어간다
2-1) 이는 infer_tool의 line 257에서 확인해볼 수 있다
3) Hubert 모델의 코드는 preprocessing.hubertinfer에 있다
3-1) 거기에는 Hubert 모델의 load 함수가 있다
3-2) 거기에는 Hubert 모델의 encode 함수가 있다.
3-3) 모델의 구조 자체는 import를 확인해봐야한다
3-4) Hubert 모델은 checkpoint에 존재한다. 즉 GaussianDiffusion 모델 ckpt에 포함 x