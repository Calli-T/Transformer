몇 가지 테스트를 해봤는데,
opencpop으로 fengtimo의 노래를 변환했을 때는 아주 잘되었다
즉, 메인 모델의 구조 자체는 아무 문제가 없다
그럼 김창섭목소리가 구리게 나온데는 몇 가지 가설을 세워볼 수가 있는데

1. 학습데이터 문제
cpop모델은 중국어 여성 전문 가수가 부른 100곡의 데이터 + 24만번의 학습이다
학습 데이터에는 대체 무슨 문제가?
    1-1. 음역대의 문제인가?
    김창섭 방송은 모든 목소리가 조곤조곤 하므로,
    넓은 음역폭이 존재하지 않는다
    https://www.youtube.com/watch?v=9pqhkLc6g1U
    많은 Diff-SVC 모델의 결과물이 고음을 못지르는 이유가 설마?

    1-2.검증 및 해결방법은?
    2개정도 생각해볼 수 있는데
    음역대가 넓은 가수의 보이스를 모조리 긁어 모은다
    +- 6 key에 대한 Augmentation을 실시한다
    augmentation은 음 올릴 때 창법을 아예 못가져올 수 있지않은가?



2. vocoder 문제
사실 Nsf-hifigan의 학습이 구린게 아닌가? 하는 가설
사용된 모델은 0109_hifigan_bigpopcs_hop128인데,
-> 반론: 이러면 같은 보코더를 사용하는 taffy118k의 성능이 구린 이유를 알 수가 없다
설마 학습 횟수 문제인가? taffy데이터셋이 없으니 taffy를 240k로 만들어 확인도 못함



1229의 리스트에 적힌 문제들을 냅두고 일단 padding문제부터 해결한다
출력물을 자르는건 diffusion class 내부에 만들것
문제는 loss