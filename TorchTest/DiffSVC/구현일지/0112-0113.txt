opencpop으로 하니 그냥 자아아알 된다
아마도, hubert 문제인듯하다
기존 hubert가 어떤 코드를 쓰는지 잘 확인해보고 개조해보자
참고로 중국어 hubert로 학습한건 infer는 일본어를 해도 잘 되더라

할일
1. 기존 HuBERT 모델 규격 파악,
HuBERT 한국어, 영어, 일본어 등 모델로 교체,
교체한 언어를 사용하는 화자의 목소리로 학습 후 테스트
2. dB정규화할 때, train 말고 infer쪽에도 norm 했다가 denorm하는 코드 제작
3. 그 crepe 다른 방법없나? 그거 너무 오래걸리는데 다른 방안을 찾아보자
4. 이론 요약

영어 HuBERT는 LibriSpeech dataset으로 학습한 facebook의 버전이 있다
후속작은 다중 언어로 학습했으니 잘 구분하고 가져갈것
일단 주소 여기
https://huggingface.co/facebook/hubert-large-ll60k

일단 HuBERT soft는 HuBERT base 기반 모델이며, 뭔가 연속적으로 만들었다고 하는데 그 구조를 파악해보자

일단 음원 읽기 일원화를 위해서는, 함수의 기능을 여럿으로 쪼개서 load를 따로 둘 필요가
있으나... 그러나 wav2spec에서 읽어오고, stft설정에 맞춰 'torch tensor'로
읽었다가 stft작업 끝나고 numpy로 넘기므로, 완전한 분리는 무리다
따라서 조건 중 어디서 읽어오는지 파악한다음, wav2spec에서 넘겨주는 방식을 취한다
먼저 f0는 wav, mel 모두 받으며, wav2spec에서 나온걸 받으니 문제 x
mel2ph는 mel, hubert를 받으며, 다른데서 받으니 문제 x
mel, wav는 뭐 말그대로 wav2spec에서 나온다
hubert만이 문제인듯하다

----- 0113 -----

일단 hubert를 처리하는 코드는
hubert_model.py의 229 line부터,
diffusion.py의 160 line부터,

근데 다른데서는 sr을 원본 그대로 가져오고,
hubert는 16000으로 취급한다
원본 sr를 줘야 hubert에서 16k로 바꿀 텐데, 그냥 두 번 읽게 두는게
코드 안박살날 일이다
-> 아니면 librosa.road만 따로 어디 분리해야하는데, 그건
hparams의 값이다
-> 어? hparams['audio_sample_rate']를 가져와볼까
일단 fname대신 wav를 보내는 것으로 해결보았으나,
batch단위로 하는건 아니다
이건 wav_list를 통째로 torch로 보내고, 그걸 [B, C, T]텐서로 바꿔줘야한다
원본은 T 텐서를 그저 [1, 1, T]로 unsqueeze할 뿐이라서 단일 B에만 적용시켜준다 -> 이건 hubert코드 바꾸고 나서 처리할것
할일 1줄요약: hubert batch처리 가능하도록 변경하기

일단 embedding 모델의 구조를 알아야 hubert를 다차원으로 사용하던가 할 수 있겠더라
일단 hubert모델을 갈아끼우더라도, 256차원의 출력을 유지하긴 해야겠다
hubert base는 원래 768 차원의 출력을 하는데, 이를 fc layer로 256차원으로 줄여버린다(아마 모델 설정이 그러할 것이다)

할일:
hubert soft(base)를 hubert soft(on large/xlarge)로 바꾸기
일단 할일은 hubert large/xlarge 코드 가져오기
코드에 맞는 모델(언어도 맞아야함) 가져오기
코드에 맞는 모델 soft화/256차원으로 맞추기
맞춘 hubert에다 diffusion/hubertinfer/hubertencoder 파일 모두 변형하기
변형 끝나면 학습하기