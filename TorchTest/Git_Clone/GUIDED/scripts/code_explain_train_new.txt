일단 classfier_train/sample.py말고 일반 image_train이나 image_sample.py은 IDDPM이나 GUIDED나 코드에 차이가 아예없다
(호출하는 함수나 클래스 세부는 다를 수 있다)


{ # image_train.py
    IDDPM 코드랑 다른점

    1. 매개변수 파싱
    각각의 script_util.py의 model_and_diffusion_defaults()에서 차이가 생겼다. 일일히 서술할 수는 없고 느낌표로 표기
    확산 관련 내용은 diffusion_defaults()라는 새로운 함수로 빠졌음, 함수 내에서 호출해서 갱신

    2. dist_util.py에 분산 처리를 지원하는 것은 똑같으나, 환경 변수(쿠다 장치 수)를 가져오는 한 줄이 추가되었다
    또한 load_state_dict가 상당히 변경되었으나, 나중에 확인 할 내용으로 둔다.

    3. 로그 따기
    뭐 별 차이가 없어보임, 패스(코드가 아예 같을 가능성도 존재함)

    4. 모델과 확산 클래스 생성
    sigma_small과 learn_sigma는 (이미지? 잡음? 어느쪽인지는 모르겠다 아마 이미지의 분포) 분산을 학습할 것인가에 관한 내용인듯하다
    그리고 sigma_small이 create_model_and_diffusion함수의 params에서 사라져있으며, diff 생성함수에는 default값으로 되어있다
    ※ learn_sigma는 예제에서 주로 True로 되어있다, 그러나 default값이 False
    ※※ sigma_small 값은 동작에서 learn_sigma True의 경우에는 그냥 묻힌다

    { # create_model
        channel_mult, num_head_channels, resblock_updown, use_fp16, use_new_attention_order 이 5개의 매개변수는 원래 없던것이다
        그리고 모두 create_model_and_diffusion 모델의 매개변수이다.

        channel_mult: IDDPM에도 있는 것이나 커스텀이 가능해졌다. 아무것도 안주면 기본 값을 주게 설정되었으며 그 내용은 IDDPM의 것과 같다.
                        기본적으로 UNet Model에서 채널 개수 배율(과 단계수)을 올리는데 사용하는 값들이다
        num_head_channels: UNet에서 Attention channel의 개수를 지정할 때 사용하는 매개변수이다. class AttentionBlock에서 사용되며,
                        채널 수 / 해드 당 채널 수로 멀티헤드의 헤드 개수도 지정해준다(헤드수가 -1로 들어올 때만 그러하다).
                        코드에 변경이 있으므로 나중에 다시 확인해 볼 필요가 있다. 아마 헤드 당 채널을 표현할 듯?
        use_new_attention_order: Attention의 legacy와 일반의 구분인듯하다, 주석에는 qkv를 head보다 먼저 split하면 일반을 사용한다
                        추후 내용 확인 필요
        use_fp16: 뭔지 안봐도 뻔하다
        resblock_updown: 주석에, 잔차 블럭을 업/다운 샘플링에 사용하느냐를 적어놨다. 그냥 잔차블럭도 여러군데 사용되서 그냥 사용하는놈도 있고
                        up/down으로 사용되는 놈도 있으니 구분 필요, class ResBlock의 매개변수에 적어놨다. default 값 False
    }

    { # create_guassian_diffusion
        매개변수는 차이가없다. (함수 호출시 sigma_small의 값만 안주는거 말고는 차이가 없다)
        마찬가지로 해당 함수가 건네주는 SpacedDiffusion의 매개변수도 차이가 없다

        그러나 SDiff class가 상속하는 GaussianDiffusion class의 경우 존재한다
        {   # class Gaussian Diffusion

            { # condition_mean
                주석: x에 대한 조건부 로그 가능도의 기울기를 계산하는 조건 함수가 주어진 상태에서 이전 단계의 평균을 구합니다
                특히 조건 함수는 grad(log(p(y|x)))를 계산하고 y에 대한 조건을 지정하려 합니다. -> 이게 뭔 소리지 ???
                이건 솔-딕스타인의 조건 전략을 사용합니다

                내용은 cond_fn에 매개변수로 x와, 스케일된 타임스탭과(실제로는 오버라이딩된 함수가 동작), 모델 인자를 넣고 gradient를 뽑아서,
                mean에 var와 gradient를 곱한것을 더해 새로운 mean을 만들고, 이를 반환한다
                -> 이게 대체 뭐하는 짓이지
                ???

                일단 샘플링에 사용된다. cond_fn가 존재한다면 분포의 평균을 함수에 맞게 살짝 바꾸어 처리한다 p_sample에서 사용
            }
            { # condition_score
                주석: 모델의 점수 함수가 조건 함수에 의해 조건화 되면, p_mean_variance 출력이 무엇인지를 계산합니다. -> ???
                condition_mean 함수와는 달리 이건 Song과 그외 다수의 조건화 전략을 사용합니다.

                alpha_bar를 alphas_cumprod와, 추출용함수등을 사용해 가져온 다음
                ???
                ???
                ???
                ???
                ???
                DDIM에 쓰인다, DDPM에는 안쓰이더라, 나중에 이론적 기반을 다시 살펴보러 갈 때 알아보자
                ddim_sample에서 사용
            }
            전체적으로 호출-> 호출 하는 과정에서 cond_fn이 존재할 경우 샘플링 함수에서 다르게 처리하게 만드는거 말고는 IDDPM과 동일
        }
    }

    5. 데이터로더
    별 차이는 없으나 이미지 증강을 위한 자르기, 뒤집기 옵션이 추가로 생겼고 이에 맞춰 코드가 일부 추가되거나 변경되었다

    6. TrainLoop
    fp16_util의 함수가 MixedPrecisionTrainer로 대거 통합됨, 모델의 패러미터나 저장이나 최적화 함수등 원래 하던 것들의 대부분이
    해당 클래스의 인스턴스 self.mp_trainer로 선언되어 TrainLoop class의 필드로 들어가고, 이를 통해 처리된다
    나중에 코드의 차이점을 자세히 살펴볼 필요가 있겠음 ???
}

{   # classifier_train.py
    주석: (ImageNet의?) 잡음낀 이미지에 대한 분류기를 학습합니다.
    classifier_sample에서 모델을 2개 꺼내쓰는것으로 보아, 확산 과정에서 잡음낀이미지를 분류하는 모델을 따로두어
    해당 모델이 확산 모델을 돕도록 하는 것으로 추측
    이 추측이 맞다면,

    코드 상에서 image_train.py과의 차이는 다음과 같다

    1. 매개변수 파싱
    model_and_diffusion_defaults()를 쓰지 않고 classifier_and_diffusion_defaults()를 사용한다.
    {   # classifier_and_diffusion_defaults()
        일반 매개변수 리셋 함수랑 같은데, classifier_defaults 함수의 내용이 몇몇 추가된다. (분류기 모델 학습용 코드인듯???, 모델도 2개 동시에 사용함)
        매개변수 내용은 여러가지가 있으나 모델 학습할 때 내용을 살펴보고 후술함
    }

    2. 병렬처리와 3. 로그 따기는 별 차이가 없어보인다

    4. 모델과 확산 클래스 선언
    create_model_and_diffusion()를 쓰지않고, create_classifier_and_diffusion() 사용한다
    script_util.py의 create_classifier_and_diffusion부터 다시 시작

    { # create_classifier_and_diffusion
        해당 함수는 분류 모델과 확산 클래스를 반환한다
        매개변수 파싱과정에서 classifier_defaults()으로 가져온 매개변수들이 분류기를 제작하는 create_classifier로 들어가 분류기를 제작한다

        {   # create_classifier
            반쪽짜리 UNet(EncoderUNet)을 반환하는 함수이다

            채널에 곱해지는 수와 그 층의 개수는 이미지 크기에 따라 결정되도록 코드가 짜여있고,
            다운 샘플링 매개변수는 여기에서 split 해서 넣는다

            {   # class EncoderUNetModel
                말그대로 인코딩 기능만 존재하는 UNet이다

                ※ 일반 UNet과 공유하는 특이한 사항이 하나 발견되었는데, resblock_updown이라는 매개변수가 존재한다
                해당 매개변수는 False일 경우에만 추가 다운/업 샘플링을 진행하는데, True의 경우에는 아무일도 일어나지 않는다,
                그러나, ResBlock 자체에 다운/업 샘플링 기능을 내장하고 있고 매개변수 up과 down으로 이를 제어한다.

                일반 UNet의 Input-middle블럭까지 존재한다.
                그러나 끝에 풀링->flatten 하여 out_channels 만큼의 특징 벡터를 뽑아내는 층이 따로 존재하며,
                그 방법도 adaptive, attention, spatial, spatial_v2로 다양하게 존재한다
                이는 일반 UNet과 공유하지 않는 계층이며, 클래스 default 값은 adaptive이다,
                그러나 매개변수 파싱에서의 값으로 덮어지며 이쪽은 기본값이 attention이다.
                즉, 어텐션 메커니즘을 적용한 풀링으로 추측할 수 있다.
            }
        }

        반환은 classifier와 diffusion을 반환한다.
    }

    5. sampler
    sampler를 만드는 함수는 동일한듯하다
    그러나 args.noised True(default 값임)인 경우에만 동작하도록 되어있다.
    아래 구간에 args.noised가 True 일 경우만 샘플링한다 ???

    ※ Sampler의 경우, 주석에서는 중요도 샘플링(??? 통계학 용어인듯 알아보자)을 위한 타임 스탭을 가져온다고하는데, Uniform의 경우 동작 방식이 이렇다
    diffusion_steps에 따라(기본 값 1000, 매개변수로 들어옴) (0, 해당값] 사이의 인덱스를 정한다음
    (1/해당값) * index를 재매개변수화 트릭에 사용할 alpha_t_bar(=cumprod)즉 잡음 비로 사용하는것이다.
    이 때 각 단계의 인덱스의 뽑힐 확률이 모두 동일하므로 Uniform인것으로 추측
    요약: 이 sampler는 x_T의 잡음비(indices of alpha_cumprod)를 뽑는데 사용함

    noise가 False일 경우 0으로만 도배되는데, 0단계의 잡음은 0이므로 아마 잡음이 없는 이미지를 훈련할 때의 경우로 추측함???

    6. resume_step 관련 코드
    학습 도중인 모델을 가져온 경우 단계와 매개변수를 가져온다
    원래 다른곳에 있던 코드인데 분류기 모델 같은 경우는 학습도 그렇고 한 파일에서 모두 처리하는듯하다

    7. sync_params
    분산학습 관련 코드인듯???
    나중에 알아보자
    코드 자체는 다른 랭크에 텐서를 전파해서 모두에게 복사하는 코드이다
    랭크는 프로세스 id를 의미하는듯하다
    주석에는 바른 EMA와 fp16을 만드는데 필요하다가 되어있다. 이경우, 분산학습 관련코드가 아닐수도 있겠다???

    8. class MixedPrecisionTrainer
    분류기? EncoderUNet(= half unet + ffn)? 를 학습 시키는(x) 시키는데 필요한(o) 클래스이다.
    lg_loss_scale이 뭘까 ???
    정작 학습 step 돌리는 코드는 같은 파일이 아니라 calssifier_train.py에 있다

    9. DDP
    병렬 학습용 모듈인 DDP에 모델을 래핑?한다
    위 mp_trainer랑 호환이 되는 모양이다
    IDDPM의 경우 train_util.py의 trainLoop에 존재하던 코드이다. (classifier 말고 확산 모델 자체는 아직도 TrainLoop 내에서 래핑하긴 한다)
    아무래도 classifier의 학습에 관한 사항은 classifier에 대부분 집어 넣은듯하다

   data_loader는 생략
   특이사항으로는 validation data를 다른 디렉터리에 냅두는것이 가능하고 관련 args의 매개변수도 존재함

    10. 최적화 기법 opt 설정
    AdamW를 사용한다.
    위 Mixed 어쩌고 클래스에서 파라미터를 내뱉는 get에 해당하는 함수가 존재하는데, 모델의 매개변수를 넣어 줄 때 사용한다.
    학습률은 당연히 파싱된 매개변수 값에서 가져옴, 가중치 감쇠도 마찬가지
    특이사항으로, checkpoint를 사용할 경우 최적화 기법자체도 매개변수가 있는데 그걸 가져온다.
    위 6번 코드랑 같이 보면 좋을듯

    11. def forward_backward_log()와 학습에 사용되는 for문
    분류기 모델을 학습시키는 코드로 추정함 주석을 한 줄씩 달이보자면
    {   # forward_backward_log
        학습에 사용되는 함수이며, main()안에 선언되어있고, 역시 main()안의 for문에서 호출하여 동작한다.
        하나의 배치를 가져오고, micro batch로 나누어 학습하도록 되어있다.

        batch, extra부터 batch = batch.to~~~ 코드 4줄은 데이터로더로 데이터랑 라벨 가져오는 작업

        args.noised가 true일경우 샘플러로 t값 즉 (index/numerator) of alpha_t_bar를 가져오고
        이것과 잡음섞인 이미지를 q_sample 함수에 넣어 x_0의 예측을 가져온다.
        false의 경우 그저 t를 0으로 밀 뿐이다.
        어느 경우든 (이미지, 잡음비) 쌍으로 존재하게되는데,
        잡음이 없는 이미지의 경우 확산단계가 0 즉 x_0의 이미지이므로 잡음비가 0인것을 나타내는듯하다
        alpha_t_bar가 (uniformed random numerate * 구간 크기) / 1 로 나타나므로 인덱스가 0이면 결국 잡음이 0이된다는 의미이다
        요약: 이미지의 잡음 유무를 매개변수로 기입하여 잡음비 값이 존재할지 말지를 결정하고, 이를 이미지와 한 쌍으로 묶어 학습에 활용한다.

        {
            for문에서는 split_microbatches 함수의 값에 enumerate를 붙여 반복한다
            {   # split_microbatches
                매개변수로 마이크로 배치 크기와 나머지 매개변수 모음을 받는다
                실행 예시를 살펴보면, 파싱된 args.microbatch와 배치/라벨/t(uniform index)를 넣어 실행시킨다

                배치 전체 크기는 *args[0](batch)의 길이로 파악하고
                yield를 사용하여 반복적으로 microbatch크기로 잘라 반환해준다.
            }
            요약: 배치를 마이크로 배치로 잘라서 반복 반환해주는 함수다
            이를 for문에 enumerate로 묶어 사용하며, 각 반복에 사용되는 매개변수는 인덱스/서브배치/서브라벨링/서브확산인덱스(t)다

            for문 내부는 pytorch식으로 만든 학습용 코드이다.
            모델에 logits(클래스별 확률)를 뽑아내고, 오차함수는 크로스 엔트로피를 사용하는 정석적인 구성이다.
            ※ 다만 losses가 좀 특이한데 오차/1-top/5-top을 모두 뽑아낸다 -> 그리고 그걸 로그 따는데에만 사용하고 del로 버린다
            오차의 평균을 내고, torch식 역전파 과정 zerograd -> backward -> step을 진행한다.
            ※ zerograd와 backward는 mp자체함수를 사용하며, optimizer.step도 그러하다
        }
    }

    {   # 그 아래에 있는 for문
        반복 횟수 - 여태까지 한 횟수 만큼 step을 반복하여 학습한다
        log따준다 - 정확한 코드는 뭔지 모르겠다

        파싱한 매개변수 anneal_lr가 사용된다. 존재하는 값인 경우 set_annealed_lr 함수로 어닐링을 해준다
        for문이 반복되는동안 계속 담금질을 하는 모양이다
        이론은 AdamWR, 혹은 https://hiddenbeginner.github.io/deeplearning/paperreview/2020/01/04/paper_review_AdamWR.html 를 참고하자
        set_anneal_lr함수는 pass, 나중에 알아보자???

        로그따기 -> 학습률 담금질 이후에는 학습의 스텝을 진행한다
        바로 위에서 선언된 forward_backward_log에 데이터(로더)를 집어넣기만 하면 그만이다.
        zero_grad와 backward는 해당 함수 안에서 동작하며, optimizer.step은 mp_trainer의 메서드 optimize를 실행시켜 동작한다
        위 3줄 요약: 학습합니다

        아래 if 부터 eval_interval은 검증에 관한내용이다. 조건문 자체는 val_data가 있을것과, 검증 횟수 만큼 step을 돌렸는가를 체크한다
        no_grad/eval 등 torch식 검증절차 진행함

        그 아래 if 문은 로그 따는 간격에 맞춰 로그 따는 내용이다

        그 아래 if 3종은 저장에 관련한 내용이다
        step이 0회가 아니고, get_rank가 0이며(이건 아마 분산 처리의 메인 프로세스임을 의미하는듯), 저장 간격만큼 step을 돌렸는 것을 조건으로 한다.
    }

    for문을 다돌리면 마지막 회차가 끝난 이후, 저장하며
    dist.barrier함수를 호출하는데 이건
    https://velog.io/@scyonggg/dist.getrank-0-%ED%9B%84-dist.barrier%EC%97%90%EC%84%9C-stall%EB%90%98%EB%8A%94-%ED%98%84%EC%83%81
    를 참조하도록 하자
}