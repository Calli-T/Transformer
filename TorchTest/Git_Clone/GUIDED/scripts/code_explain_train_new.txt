일단 classfier_train/sample.py말고 일반 image_train이나 image_sample.py은 IDDPM이나 GUIDED나 코드에 차이가 아예없다
(호출하는 함수나 클래스 세부는 다를 수 있다)

일단 image_train.py의 코드를 추적하면서 차이점을 확인해보는 과정을 거침

1. 매개변수 파싱
각각의 script_util.py의 model_and_diffusion_defaults()에서 차이가 생겼다. 일일히 서술할 수는 없고 느낌표로 표기
확산 관련 내용은 diffusion_defaults()라는 새로운 함수로 빠졌음, 함수 내에서 호출해서 갱신

2. dist_util.py에 분산 처리를 지원하는 것은 똑같으나, 환경 변수(쿠다 장치 수)를 가져오는 한 줄이 추가되었다
또한 load_state_dict가 상당히 변경되었으나, 추후에 확인 할 내용으로 둔다.

3. 로그 따기
뭐 별 차이가 없어보임, 패스(코드가 아예 같을 가능성도 존재함)

4. 모델과 확산 클래스 생성
sigma_small과 learn_sigma는 (이미지? 잡음? 어느쪽인지는 모르겠다 아마 이미지의 분포) 분산을 학습할 것인가에 관한 내용인듯하다
그리고 sigma_small이 create_model_and_diffusion함수의 params에서 사라져있으며, diff 생성함수에는 default값으로 되어있다
※ learn_sigma는 예제에서 주로 True로 되어있다, 그러나 default값이 False
※※ sigma_small 값은 동작에서 learn_sigma True의 경우에는 그냥 묻힌다

{ # create_model
    channel_mult, num_head_channels, resblock_updown, use_fp16, use_new_attention_order 이 5개의 매개변수는 원래 없던것이다
    그리고 모두 create_model_and_diffusion 모델의 매개변수이다.

    channel_mult: IDDPM에도 있는 것이나 커스텀이 가능해졌다. 아무것도 안주면 기본 값을 주게 설정되었으며 그 내용은 IDDPM의 것과 같다.
                    기본적으로 UNet Model에서 채널 개수 배율(과 단계수)을 올리는데 사용하는 값들이다
}