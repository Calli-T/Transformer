논문의 내용이다
https://arxiv.org/pdf/2006.11239
https://velog.io/@philiplee_235/Denoising-Diffusion-Probabilistic-Models

둘을 참고 했다

-----

DPM은 매개변수화 된 마르코프 체인이다.
`일정 시간 이후의 데이터에 대응되는 샘플`을 생성하는 `변분 추론`을 이용하여 학습되었다.
-> 이게 대체 뭔 소린가, `일정 시간`은 diffusion time을 / 변분 추론은 MLE 파생 방식이니 따로 알아보자
->-> 변분 추론이 뭔지는 알아봤는데 사용방법이 서로 다 다르니 생성모델별로 그 방법에 대해서나 알아봅시다

여튼 체인간의 전이? 변이?는 확산 과정을 역행하도록 학습한다고한다
-> 실제로도 정방향은 재매개변수화트릭으로 딸깍하는데, 역방향은 반복문 돌리더라, 그거 학습과정에 포함됨
->-> 확산 과정은 신호가 사라지지 않을 때까지 데이터에 잡음을 추가하는 '마르코프' 과정이라고 한다, 왜 마르코프?
->->-> 이 과정이 마르코프 체인인 이유는 2가지로 요약된다.
1. x_t는 오로지 x_t-1와 노이즈 ε에만 의존한다.
2. 노이즈 ε은 독립적이며 그 평균이 정규 분포를 따른다(행렬 곱으로 하던 그건 아닌모양, 정규분포는 확률밀도함수와 관련있다).
즉, 과거 상태와 무관하게 상태 전이가 현재 상태에만 기반한 확률적 전이이다

만약 확산 과정에서 작은 가우시안 잡음이 지속적으로 더해진다면,(forward)
표본뜨기가 일어나는 chain transition(사슬 전이, 아마 reverse process를 가리키는듯)를
조건부 가우스 잡음이 추가되는 과정으로 볼 수 있으며,
인공 신경망 매개화를 부분적으로 적용할 수 있다.
->역방향에서 조건부 가우스 잡음을 추가하는 과정은 AI를 때려박을 수 있다... 뭐 그런 얘기같다

확산모델은 똑바로 정의되고 효율적인 학습이 되지만 퀄리티가 어쩌고저쩌고... 생략

확산 모델에 특정 매개화를 적용하는 것은 다음 두 경우와 동치임을 보인다고 한다.
case1: 훈련 중 여러 잡음 단계와 denoising score matching
case2: 샘플링 중 annealed Langevin dynamics
-> 뭘 매개변수화 하는지랑, dsm과 ald???가 뭔지부터 알아야한다
->->https://wikidocs.net/230559 ald은 여기에 있다, score-based 모델과 연관이 있는 모양이다
->->-> DSM과 score-based models는 확률 분포에서 나온 스코어 함수를 학습하는 것을 목표로 하며,
스코어 함수는 log p(x)의 미분이다. 즉 s(x) = ∇_x(log p(x)) / 둘 다 자세한건 모델을 통해 알아보던지 다로 알아보던지하자