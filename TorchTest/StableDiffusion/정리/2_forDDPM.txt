논문의 내용이다
https://arxiv.org/pdf/2006.11239
https://velog.io/@philiplee_235/Denoising-Diffusion-Probabilistic-Models

둘을 참고 했다

----- 서론 -----

DPM은 매개변수화 된 마르코프 체인이다.
`일정 시간 이후의 데이터에 대응되는 샘플`을 생성하는 `변분 추론`을 이용하여 학습되었다.
-> 이게 대체 뭔 소린가, `일정 시간`은 diffusion time을 / 변분 추론은 MLE 파생 방식이니 따로 알아보자
->-> 변분 추론이 뭔지는 알아봤는데 사용방법이 서로 다 다르니 생성모델별로 그 방법에 대해서나 알아봅시다

여튼 체인간의 전이? 변이?는 확산 과정을 역행하도록 학습한다고한다
-> 실제로도 정방향은 재매개변수화트릭으로 딸깍하는데, 역방향은 반복문 돌리더라, 그거 학습과정에 포함됨
->-> 확산 과정은 신호가 사라지지 않을 때까지 데이터에 잡음을 추가하는 '마르코프' 과정이라고 한다, 왜 마르코프?
->->-> 이 과정이 마르코프 체인인 이유는 2가지로 요약된다.
1. x_t는 오로지 x_t-1와 노이즈 ε에만 의존한다.
2. 노이즈 ε은 독립적이며 그 평균이 정규 분포를 따른다(행렬 곱으로 하던 그건 아닌모양, 정규분포는 확률밀도함수와 관련있다).
즉, 과거 상태와 무관하게 상태 전이가 현재 상태에만 기반한 확률적 전이이다

만약 확산 과정에서 작은 가우시안 잡음이 지속적으로 더해진다면,(forward)
표본뜨기가 일어나는 chain transition(사슬 전이, 아마 reverse process를 가리키는듯)를
조건부 가우스 잡음이 추가되는 과정으로 볼 수 있으며,
인공 신경망 매개화를 부분적으로 적용할 수 있다.
->역방향에서 조건부 가우스 잡음을 추가하는 과정은 AI를 때려박을 수 있다... 뭐 그런 얘기같다

확산모델은 똑바로 정의되고 효율적인 학습이 되지만 퀄리티가 어쩌고저쩌고... 생략

확산 모델에 특정 매개화를 적용하는 것은 다음 두 경우와 동치임을 보인다고 한다.
case1: 훈련 중 여러 잡음 단계와 denoising score matching
case2: 샘플링 중 annealed Langevin dynamics
-> 뭘 매개변수화 하는지랑, dsm과 ald???가 뭔지부터 알아야한다
->->https://wikidocs.net/230559 ald은 여기에 있다, score-based 모델과 연관이 있는 모양이다
->->-> DSM과 score-based models는 확률 분포에서 나온 스코어 함수를 학습하는 것을 목표로 하며,
스코어 함수는 log p(x)의 미분이다. 즉 s(x) = ∇_x(log p(x)) / 둘 다 자세한건 모델을 통해 알아보던지 다로 알아보던지하자
구체적인 방식은 4.2에 있다고 한다

그 외 내용들
DM은 양질의 sample을 생성하지만 다른 모델들과 비교해서log-likelyhood
이미지의 미세한 부분까지 묘사할 수 있다더라. 논문에서 손실 압축이라는 개념으로 보다 정교하게 분석한다고함
DM의 샘플링 과정은 점진적 디코딩의 한 종류이다(그리고 순차적으로 일어나는 자기회귀와 유사하며 자기회귀에서 일반적으로 일어나는 현상의 일반화 라고한다)
점진적 디코딩은 불완전한 이미지에서 이미지의 일부를 증분적으로 디코딩 하는 기능이라고 한다



----- 배경 -----
- 역과정 -
확산 모델은 잠재 변수를 가지는 모델이며 그 형태는 다음과 같다고 한다.
p_θ(x_0) = sympy.integrate(p_θ(x_0:T) dx_1:T)
x_1, x_2,...,x_T는 data x_0~q(x_0)와 같은 차원을 지니는 잠재 변수이다.
-> 아마 latent space의 벡터 길이, 측 차원을 얘기하는 모양이다
->-> q(x_0)는 원본 데이터의 분포를 의미한다. ※ 단, 원본이 아닌 근사치이다. 이를 처리하는 방법은 후술
q자체가 정방향 확산 과정을 의미하는 것이 '아니'며
q(x_1:T|x_0)가 정방향 확산 과정이다. 이를 diffusion process, forward pass 또는 approximate posterior라고한다

p_θ(x_0:T)는 결합 분포이며, 역과정으로 지칭한다.
-> 결합 분포에 대해서 자세하게 알아보자 주소는
https://hyunhp.tistory.com/175
https://ko.wikipedia.org/wiki/%EA%B2%B0%ED%95%A9%EB%B6%84%ED%8F%AC
결론적으로 결합분포란 확률 변수가 여러 개일 때 이들을 함께 고려하는 확률 분포라고 한다.
확률 분포의 일종이므로 결합 확률 분포라고도 하는듯
->-> 이산일 때와 연속일 때가 조금 다른듯 하다
이산의 경우 P(X = x and Y = y)로 표기한다 ※ 전통의 기호 &로 and를 대체 하는 경우도 많더라
P(X = x and Y = y) = P(Y = y|X = x)P(X = x) = P(X = X|Y = y)P(Y = y)

그리고 역과정 즉 p_θ(x_0:T)는
Gaussian transition을 배운 마르코프 체인으로 정의된다.
가우시안 전이(Gaussian transition)는 p(x_T) = N(x_T;0, I)로 시작한다.
-> p(x_T)는 x_T의 (이미지이니 픽셀의 값에 대한) 분포이며, 평균이 0이고 공분산 행렬이 단위 벡터인 '다변량 표준 정규 분포'이다
->-> 정방향 프로세스는 정규분포의 선형 결합에 관한 법칙에 따라 N(0, I)가 유지되도록 설계된다
p_θ(x_0:T) := p(x_T) * Π_product(t=1, T, p_θ(x_t-1|x_t))
p(x_T) = N(x_T;0, I)
p_θ(x_t-1|x_t) := N(x_t-1;μ_θ(x_t, t), Σ(x_t, t))
-> 세 번째 식의 좌변은 주어진 상태 x_t에서 이전 상태 x_t-1의 확률 분포를 나타낸다.
우변은 평균 μ_θ(x_t, t)과 공분산 행렬 Σ(x_t, t)를 갖는 정규 분포이며, θ를 모수로 사용한다
첫 째식은 전체 역과정에 관한 식이며, 세 번째 식을 반복한 것과 p(x_t)를 곱한것이다
->-> 이 식들의 나온 이론적 배경은 SDEs나 히든마르코프같은 심연의 지식을 포함한다. 나중에 알아보자???
하여튼 역과정 식이 저러하다는 배경만 알고 있자
결론: 역과정 식은 저리 생겼다

- 정과정 -
Diffusion과 다른 잠재 변수 모델과의 차이점은 근사 사후확률 q(x_1:t|x_0)에 있으며
이를 forward pass 또는 확산 과정이라고한다
(마르코프 체인 과정을 따르며 가우시안 잡음의 분산은 Β_1, Β_2, ..., Β_T에 의해 결정된다)
이는 마르코프 체인에 고정되어잇으며, 점진적으로 가우시안 잡음을 분산 스케줄 Β_1, Β_2, ..., Β_T에 따라 데이터에 추가한다

구체적인 수식은 다음과 같다
q(x_1:t|x_0) = Π_product(t=1, T, x_t|x_t-1)
q(x_t|x_t-1) := N(x_t; sqrt(1-Β_t)*x_t-1, Β_tI)
x_0 ~ q(x_0)
-> x_0는 확률분포 q(x_0)에서 나왔다. ※ 초기 이미지를 정규화 해서 q(x_0)를 다변량 표준 정규 분포로 두고 시작하는게 맞던가???
->-> x_t-1가 주어졌을 때 x_t의 조건부 확률에 관한 식에서 x_t에 관한 식을 세울 수 있다
x_t = sqrt(1-Β_t) * x_t-1 + ε ※ ε ~ N(0, Β_tI)
식의 좌우의 평균은 모두 0인 값이고, 분산은 각각 1-B_t과 B_t이므로 x_t는 다변량 표준 정규 분포를 따른다
즉 저 조건부 확률은 x_t-1가 다변량 표준 정규 분포를 따를 때 x_t도 그러하도록 스케일링한다.

훈련은 음의 로그 가능에 대한 일반적인 변분 경계를 최적화하는 방향으로 수행되었다.
그리고 그 식은 다음과 같다 ※ GPT피셜, 이는 ELBO와 젠슨 부등식의 응용이 맞다고 한다. 식이 비슷해서 넣어봄
E[-log p_θ(x_0)] <= E_q[-log p_θ(x_0:T) / q(x1:T|x_0)]
-> (GPT 피셜) 좌변은 x_0에 대한 모델의 로그 우도의 기댓값이며
우변은 변분 분포 q(x_1:T|x_0)와 결합 분포 p_θ(x_0:T) 사이의 차이를 나타내는 항이다.
※ 우변은 KL 발산의 변형이다

또한 우변은 다음과 같이 변형할 수 있다
E_q[-log p_θ(x_0:T) / q(x1:T|x_0)]
= E_q[-log p(x_T) - Σ_sum(t=1, T, log(p_θ(x_t-1|x_t) / q(x_t|x_t-1)) )]
-> 이는 역과정 식에서 시작부분 p(x_T)분포만 빼고, 각 과정을 sum(로그곱은 합이고, 각 식은 곱으로 되어있으므로)한것과같다
그리고 저 식을 L이라고 정의하더라 ※ (GPT 피셜) 사후 분포/증거 하한에 관련된 함수라고 하더라

정방향 과정의 분산인 B_t는 재매개변수화로 학습하거나 하이퍼파라미터 상수로 둘 수 있다.
그리고 역방향 과정의 표현력들은 p_θ(x_t-1|x_t)에 담긴 가우스 조건의 선택이 담긴 부분으로 보장되었습니다.
-> 역방향 과정에서 선택하는 조건들이 이미지 생성 능력을 좌지우지하는 모양이다???
왜냐하면 두 과정은 B_T가 작을 때 같은 함수 형태를 가지고 있기 때문입니다.
정방향 과정의 주목할만한 성질은 닫힌 형태의 임의 시간단계 t에
표본 x_t에 바로 접근할 수 있다는 겁니다.
-> admit이 ~에 접근할 수단이 되다로 사용된 모양이다.
이는 수식 α_t:=1-Β_t, a_t_bar:=Π_product(s=1, t, a_s)을 사용하여, 수식
q(x_t|x_0) = N(x_t; sqrt(a_t_bar)x_0, (1-a_t_bar)I
-> 정규분포에 가법성에 따라 단계를 스킵하여 정방향 확산을 하나로 처리하는 수식, 원리는 논문에없다
그리고 x_t는 sqrt(a_t_bar)x_0 + sqrt(1-a_t_bar)*ε ※ ε ~ N(0, I)
로 나타낼 수 있다.

그러므로 효과적인 학습은 L의 무작위 조건들을 확률적 경사하강(SGD)으로 최적화하는 것으로 이루어진다.
-> 이거 오차역전파 최적화에 쓴다는 얘기가 아닐 가능성이 있다. 변분 추론 중에 이거 사용하는
방법이 있더라. https://ratsgo.github.io/generative%20model/2017/12/19/vi/
L을 다시 작성하여 분산을 감소시키면 추가 개선이 이루어진다. L의 식은 다음과 같다
-> 유도 과정이 길다보니 논문에도 부록에 있더라
위 식에서 L부터 시작한다
E_q[-log p_θ(x_0:T) / q(x1:T|x_0)]
= E_q[-log p(x_T) - Σ_sum(t=1, T, log(p_θ(x_t-1|x_t) / q(x_t|x_t-1)) )]
= E_q[-log p(x_T) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t) / q(x_t|x_t-1))) - log(p_θ(x_0|x_1)/q(x_1|x_0))] ※ 역방향 마지막 과정/정방향 첫 과정에 해당하는 t=1의 사례를 따로 뺐다
= E_q[-log p(x_T) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t)/q(x_t-1|x_t, x_0) * q(x_t-1|x_0)/q(x_1|x_0))) - log(p_θ(x_0|x_1)/q(x_1|x_0))] ※ (Gemini) 이는 신묘한 마르코프 트릭을 사용하였다, 아래에 후첨 (20)
= E_q[-log p(x_T) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t)/q(x_t-1|x_t, x_0))) - Σ_sum(t=2, T, log(q(x_t-1|x_0)/q(x_t|x_0)) )  - log(p_θ(x_0|x_1)) + log(q(x_1|x_0))] ※ 20과 21번식의 중간단계, 소거를 위해 찢어놨다
= E_q[-log p(x_T) - Σ_sum(t=2, T, log(q(x_t-1|x_0)/q(x_t|x_0)) ) + log(q(x_1|x_0)) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t)/q(x_t-1|x_t, x_0))) - log(p_θ(x_0|x_1))]
여기서 앞의 로그 세 항은
log 1/p(x_T) * [q(x_2|x_0)/q(x_1|x_0) * q(x_3|x_0)/q(x_2|x_0) ... q(x_T|x_0)] * q(x_1|x_0)
= log 1/p(x_T) * [q(x_T|x_0) / q(x_1|x_0] * q(x_1|x_0)
= log 1/p(x_T) * q(x_T|x_0)
= log q(x_T|x_0)/p(x_T)
= -log p(x_T)/q(x_T|x_0)
이를 기반으로 L의 유도 과정을 이어나가면
= E_q[-log p(x_T) - Σ_sum(t=2, T, log(q(x_t-1|x_0)/q(x_t|x_0)) ) + log(q(x_1|x_0)) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t)/q(x_t-1|x_t, x_0))) - log(p_θ(x_0|x_1))]
= E_q[-log p(x_T)/q(x_T|x_0) - Σ_sum(t=2, T, log(p_θ(x_t-1|x_t)/q(x_t-1|x_t, x_0))) - log(p_θ(x_0|x_1))]
여기서 쿨백-라이블러 발산을 적용하면 chap2의 식을 얻어낼 수 있다
DKL(q||p) = Σ_sum(x, q(x)*log(q(x)/p(x))
그럼 최종적으로
E_q[D_KL(q(x_T|x_0)||p(x_T)) + Σ_sum(t=2, T, D_KL(q(x_t-1|x_t, x_0||p_θ(x_t-1|x_t)))) - log(p_θ(x_0|x_1))]의 값을 얻게 된다 ※ q함수가 곱해지지 않고 KL발산으로 치환되는 이유는 아래의 후첨 설명 필요
여기서 첫 째항은 L_T 둘 째 항은 L_t-1, 마지막 항은 L0이다.

최종 E_q식은 KL 발산을 사용하여 p_θ(x_t-1|x_t)를 정방향 과정의 사후확률과 직접 비교하는데, 이는 x_0가 주어졌을 때 가능하다
-> 정방향 확산 과정에서 사용하던 분포 q에서 위치를 뒤집어 사후 확률로 만든다
x_t와 x_0를 조건으로 하여 x_t-1를 만들어내는 q분포와(q의 사후확률) 원래 역방향 확산 과정 p(x_t-1|x_t)를 KL발산으로 비교해야하고, 이건 x_0값이 존재해야 해석가능하다고 한다.
->-> 여기서 x_t에서 x_0로 갔다가 x_t-1로 가는 이론적 기반이 존재하게 된걸지도????
q(x_t-1|x_t, x_0) = N(x_t-1; ~μ(x_t, x_0), ~B_t * I)
where ~μ(x_t, x_0) = (sqrt(α_t-1_bar) * β)/(1-α_t_bar) * x_0 + (sqrt(a_t)*(1-a_t-1_bar)/(1-a_t_bar))*x_t and ~β_t = (1-a_t-1_bar)/(1-a_t_bar) * β_t
-> 이 식, x_0과 x_t의 가중 평균에관한 내용인 모양이다.
->-> 알파 베타 값은 잡음/신호비이며 linear나 cosine등 확산 과정에 따라 다를 수 있다.
->->-> IDDPM 코드 같은 경우는 긴 배열에다가 자르고 붙이던 그 녀석들 같은데? 이를 근사하여 사용하는 경우가 있으니 잘봐야할듯

따라서 최종 E_q식은 모든 KL 발산이 정규 분포 간의 비교이므로,
고분산 몬테카를로 추정치(이건 또 뭐야)대신 닫힌 형태의 식을 사용하여 라오-블렉웰 방식으로 계산될 수 있다.
-> 이게 뭔소린지는 차차 알아가보자












이걸 참고해봅시다
https://wikidocs.net/230583

변분 경계식 L의 유도 과정에서 (19)->(20)에는 신묘한 트릭이 적용되었다.
q(x_t-1|x_t) = q(x_t|x_t-1) * q(x_t-1) / q(x_t) ※ 베이즈 정리를 활용
q(x_t-1|x_t, x_0) = q(x_t|x_t-1, x_0) * q(x_t-1|x_0) / q(x_t|x_0) ※ x_0에 대한 조건을 위 식의 양변에 추가, DDPM은 초기 상태 x_0도 중요하기 때문?
이 때, q(x_t|x_t-1, x_0) ≈ q(x_t|x_t-1)이다.
DDPM 마르코프 체인을 가정하므로 현재 상태는 이전 상태에만 의존한다고 가정한다, 따라서 조건 2개중 x_0는 아무렴 상관없다
이를 정리하면
q(x_t|x_t-1, x_0) ≈ q(x_t|x_t-1) * q(x_t-1|x_0) / q(x_t|x_0)
<-> q(x_t|x_t-1) ≈ q(x_t|x_t-1, x_0) * q(x_t|x_0) / q(x_t-1|x_0)
<-> 1 / q(x_t|x_t-1) ≈ 1/q(x_t|x_t-1, x_0) * q(x_t-1|x_0)/q(x_t|x_0)
핵심은 베이즈 정리를 적용하여 순서를 바꾸고, 양변에 x_0조건을 붙인다음
마르코프 체인의 가정을 활용하여 조건 하나를 소거해버리는 것이다

논문의 (21)식에서 (22)식으로 넘어갈 때 로그의 마이너스를 뒤집어 분모<->분자끼리 뒤집고으면 KL발산과 유사한 항이 된다.
이 때 E_q는 Q분포에 대한 기대값을 구하므로, 그대로 KL발산으로 넘어가도 상관없는것같다. 다만 KL발산으로 치환하지 못하는 항도 있기는 하다.
KL발산은 정보이론에서 유래된 개념이다. 로그 비율 log(P(X)/Q(X))는 분표 P와 Q의 상대적 정보량을 측정하는데,
여기 E_p를 도입하여 E_p[log(P(X)/Q(X))]가 된다면, P분포 하에서 P와Q분포의 비율에 대한 로그 값의 평균을 구하는 것이라고 한다???????
이게 무슨 소린지 나중에 자세하게 알아보자?????