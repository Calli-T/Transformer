Diffusion Models Beat GANs on Image Synthesis
https://arxiv.org/pdf/2105.05233

때려치고 번역문 가져옴
https://hsejun07.tistory.com/248

초록
현행 SOTA 생성 모델보다 확산 모델이 더 우월한 이미지 견본에 도달할 수 있다

우린 이걸(우월한 이미지 견본) 일련의 절제를 통한 더 나은 구조를 찾는것으로
무조건적인(unconditional) 이미지 합성에 이것(SOTA?)을 달성하였다 -> 뭔소리야

우리는 조건부 이미지 합성을 위해
견본의 질을 분류자 지침
즉 분류기의 기울기를 사용하여
다양성과 견고함을 맞교환하는 간단하고
계산 효율적인 방법을 사용하여
견본의 질을 더욱 향상한다.
-> 뭔가 trade off인걸 잘 조절한듯?

※ FID: Frechet Inception Distance, 생성 영상의 집합과 실제 생성하고자 하는 클래스 데이터 분포간의 거리
가까울 수록 좋은 값, https://m.blog.naver.com/chrhdhkd/222013835684

그 아래는 대충 크기별 IMAGENET 데이터셋에서 FID점수 몇 점, 몇 점 나왔다는 내용과
깃허브 링크

----------------------------------------------------------------------------
1. 소개
몇 년 동안 생성 모델은 사람같은 자연어, 무한한 고품질 이미지 합성과
매우 다양한 사람말 그리고 음악 등을 생성할 수 있는 능력을 얻었다

이 모델들은 텍스트 프롬프트에서 이미지를 생성하거나 표현에서 유용한 특성을 학습하는등 다양하게 사용될 수 있다

이 모델들이 이미 현실적인 이미지와 사운드를 만들어내는데 유용할지라도,
현행 SOTA 모델을 너머의 많은 발전의 방들이 많이 있습니다.(발전할 여지가 많다는 뜻인듯)
그리고 더 나은 생성 모델은 그래픽 디자인, 게임, 음악 작업과 무수한 분야에 광범위한 충격이었을지도 모른다.

생성형 적대 신경망들은 지금 대부분의 이미지 생성 작업의 SOTA를 꽉 쥐고있고
이는 FID, IS, Precision 같은 견본 품질 척도로 계측되었다

그러나 저 척도들 가운데 어느 것들은 다양성을 전부 포착하지는 못한다
그리고 그건 생성형 적대 신경망들이 가능도 기반의 SOTA 모델들보다
다양성(= diversity)을 적게 잡아냈음을 보여왔다

더욱이 생성형 적대 신경망은 대부분 학습하기 어렵고
신경써서 선별된 hyperparamter와 regularizers(정규화하는장치, 정칙자)없이는 자주 붕괴(colllapsing, 기울기 얘기인듯?)해버린다.

생성형 적대 신경망(GAN)이 SOTA를 쥐고있을 때에는
GAN의 약점으로 인해 규모조절(scale)하고 새로운 영역(domains)들에 적용하기 어려웠습니다.

그 결과, 가능도 기반 모델로 GAN과 유사한(원문은 GAN-like)
품질을 달성하는데 많은 작업이 수행되었다.

이 모델들이 GAN보다 많은 더 많은 다양성을 잡아내고 일반적으로 더 쉽게 scale하고 학습하는 동안
시각적 견본 품질 측면에서 여전히 부족했었다

더욱이, VAE(변형 자기 부호화기)를 제외하고는
이 모델들로 샘플링하는것은 GAN보다 벽시계 시간으로 봐도(??? 많이 느리다는 뜻인가?) 느렸습니다

확산 모델은 가능도 기반 모델 종류이며 최근에 고품질 이미지를 생산하는걸 보여줬다
분포 범위나 변화없는 학습 객체, 쉬운 확장성 같은 바람직한 속성을 제공하면서 말이다 -> ???

이 모델들은 신호로부터 잡음을 점진적으로 생성하여 견본을 생성한다
그리고 그것들의 학습 객체는 재가중치화된 변형하한으로 표현될 수 있다 -> ???

(대충 LSUN이나 IMAGENET 등의 생성 데이터셋에서 GAN보다 밀렸으나
고성능 컴퓨터로 성능 개선을 했다는뜻)

upsampling하여 IMAGENET 256x256도 견본뜨기 가능
그러나 FID점수가 여전히 BIG-GAN보다는 별로라고함

GAN모델과의 점수차에 대한 가설 2개 세움
1. GAN모델이 문자그대로 빡세게 탐구되고 세련화되었음
2. GAN은 고품질 견본을 생산함으로 다양성과 견고함을 상충할 수 있음

그러나 전체 분포를 감당하지는 다루지는 못함 -> 이 부분이 확산 모델에 이득을 가져와줄것을 노렸음

먼저는 모델 구조를 개선하고 그 다음엔 다양성과 안정성의 상충의 계획을 고안한다
(대충 GAN을 뛰어넘을거라는뜻)

논문 구성은 섹션 2에서 확산 설명
섹션 3에서 FID를 향상시키는 개선 사항
섹션 4에서는 활용방법
섹션 5에서는

무조건 이미지 합성에는 구조 개선을 통해
조건 이미지 합성에 분류기 지침을 사용함으로
25회 만큼 적게 정방향 (확산 과정)을
BigGAN과 비교할만하게 FID를 유지하는것을 발견하였다 <- 이게 핵심인듯?

??? '조건부'라는 뜻은 조건부 확률을 사용하는 뜻 or 라벨링이 되어있다는 뜻으로 추측

----------------------------------------------------------------------------
2. 배경
확산 모델 요약 해줌, 수학적 디테일은 첨부 B를 읽어볼것...이라고함

높은 단계에서, 확산 모델은 점진적 잡음 과정을 역행하여
분포로부터 견본(샘플)을 떠온다

특히 샘플링은 잡음 x_T로부터 시작된다
점진적으로 적은 잡음을 가진 샘플 x_T-1, x_T-2...로 만들어진다
마지막 견본 x_0에 도달할 때까지

신호대 잡음비가 시간단계(timestep) t에 의해 결정된다면
각 단계에서 t는 특정 잡음 레벨(단계)에 상응하고,
x_t는 x_0와 잡음 ε의 혼합으로 생각될 수 있다

이 논문의 남은 부분을 위해
우리는 잡음 ε가 대각 가우시안 분포(다변량 표준 정규분포를 의미하는듯, 공분산 행렬의 대각성분만 1로 존재함)에서
나왔(drawn)다고 가정한다
(그리고 그 것이 자연적 이미지와 다양한 파생의 간편화된것에 잘 동작한다)

확산 모델은 x_t에서 약간 더 잡음이 제거된 x_t-1을 생성하는 방법을 학습한다
이 모델을 잡음낀 견본 x_t에서 잡음 성분을 예측할 수 있는 함수
엡실론_세타(x_t, t)로 매개변수화 하라

이 모델을 훈련하기 위해서는
미니 배치 안의 각 샘플(견본)은
무작위로 그려진 데이터 견본 x_0과 timestep t, 잡음 ε으로 부터 만들어져야하며
이는 함께 잡음낀 x_t를 생성한다

학습 개체는 ||(함수값 즉 예측잡음) - (실제잡음)||^2 (※ L2노름을 의미하는듯)이며
다시말해 예측 잡음과 실제 간의 MSE다

잡음 예측기로부터 잡음의 견본을 어떻게 뜨는가는 즉각적으로 명백하지는 못하다

확산 샘플링은 x_T에서 시작해서x_t에서 x_t-1을예측하는것을 반복적으로 진행하는한다
그것을 상기하면 그것은 합리적인 추정 아래에서
x_t가 주어졌을 때 x_t-1의 분포 pθ(xt−1|xt)를 대각 가우시안 N (xt−1; µθ(xt, t), Σθ(xt, t))로
모델링 할 수 있다
※ p_theta 옆 N(; 어쩌고, 저쩌고)는 확산 과정을 나타내는 함수, p_theta는 분포에서 ...하는 함수?

가우스 분포에서의 분산 (원문에서는 Sigma_theta(x_t, t)으로 적혀있음)은
알려진 상수로 고정될 수 있고,
신경망의 head(멀티 '헤드' 어텐션의 헤드인지 단순히 머리를 나타내는건지는 모름)로 나눠져 학습가능하며
확산 과정 T가 충분히 큰 수일경우, 양쪽 접근이 모두 고품질의 견본을 만들어낼 수 있습니다

????
잡음제거 확산 모델을 VAE로 해석하여 도출할수 있는
실제 variational lower bound L_vlb보다,
평균 제곱 오차 objective L_simple이 더 잘 작동한다는것을 관찰하라?

이 목적으로 학습하고 해당 샘플링 절차를 사용하는것
= 여러 노이즈 레벨로 학습된 잡음 제거 모델에서 샘플을 추출하여 고품질 이미지를 생성하는
song and ermon의 denoising score matching model

두 모델을 모두 diffusion model로 속기한다

-----
2.1 Diffusion 모델의 개선사항

???
lower bound가 뭐냐?

+++할일
분산을 상수로 고정하는게 255p에나오는 a_t와, 재매개변수화 트릭이 '맞는지'확인해보자
아무래도 '진짜 개선사항'은 3챕과 4챕에 있는모양

가중합계는 대체 뭔소린가?

non-Markovian은 대체 또 뭔가

노이즈가 0이라는 소리는 무작위 잡음얘기인가?

50회 미만은 대체 뭔소리인가

???
일단 beta_t와 ~beta_t, L_simple + λ L_vlb를 사용해
epsilon_theta(x_t, t)와 Sigma_theta(x_t, t)를 동시에 학습하는게 뭔소리인지
출력 v를 보간하는게 또 뭔소리인지는 ddpm 논문과 함께 보면서 추후에 알아보자

일단 두 종류의 함수는 모두 x_t에서 x_t-1를 만드는 과정에서 나온것으로보아
신호비와 잡음비 혹은 해당 단계에서 신호와 잡음으로 추측하며,
분산 Sigma_theta(x_t, t)를 상수로 고정하는건 학습 때 재매개변수화 트릭을 통해 사용될 α를 무작위로 뽑아 해당 학습에서 고정으로 사용하는것으로 추측한다

비마르코프 체인이 뭔지는 모르겠다만 '이 노이즈'는 DDPM에 추가되는 무작위 잡음을 얘기하는거고
그걸0으로 만들면 결정론적인 매핑이라고 한다, 그리고 그게 50미만의 샘플링에서는 적절하다고 여겨지는듯

-----
2.2
평가 척도에 관한 얘기이다
공간 특징을 사용하는 sFID라는게 있다고한다
FID는 Inception-V3 잠재공간에서 두 이미지 분포 사이의 거리에 대한 대칭 측정을 제공한다고 한다
추측하기로는 이미지를 인셉션 합성곱 신경망에 넣고 나온 특징 벡터를 코사인 내적이라도 하는 모양

그 아래에는 늘 그렇지만 한계점을 표시

----------------------------------------------------------------------------
3. 구조 개선

(대충 UNet 좋다는 내용)
UNet모델은 residual layer and downsampling conv stack을 사용하고
upsampling conv's residual layer stack을 사용
동일한 공간 크기의 레이어를 연결하는 skip connection 사용
단일 헤드로 16x16 전역 어텐션 레이어 사용, 각 잔차 블록에 시간 단계 임베딩의 투영을 추가

개선 내용 시도 5가지는
모델 크기를 상대적으로 일정하게 유지하면서? depth 대비 폭을 늘린다
어텐션 헤드 수를 늘린다
32x32/16x16/8x8 해상도 어텐션을 모두 수행
BigGAN 잔차블럭 사용 -> 이건 BigGAN 잔차블럭이 뭔지나 알아보자
잔차 연결 규모 재조정 인자(rescaling factor)를 1/√2로 한다 -> 이게 뭔소리인지 알아보자 -> 추측1 어텐션에 소프트맥스 이전의 scaling factor를 의미하는가?

https://arxiv.org/pdf/1809.11096
-> 빅간 논문이다
https://voletiv.github.io/docs/presentations/20181030_Mila_BigGAN.pdf
-> 좀 더 읽기 쉬워보이는 버전이다
https://arxiv.org/pdf/2011.13456
-> 그리고 빅간 잔차블럭을 여기 나온 방식대로 사용한다고 한다

depth늘리는건 성능 증가에 도움 되지만 너무 오래걸려서 추가실험에는 x
헤드당 64채널을 기본값으로 사용한다함(실험적으로 알게된 사실)

추가로, 적응형 그룹 정규화를 시도해본다고한다 -> 실제로 FID가 올라간다고한다
AdaGN(h, y) = y_s GroupNorm(h)+y_b로
h는 첫 째 conv에 따른 잔차 블록의 중간 활성화 ???
y는 y_s, y_b의 집합, 시간 단계 및 클래스 임베딩의 선형 투영???
-> 구조를 까봐야 알겠다

최종적으로 해상도당 2개의 잔차 블록,
헤드당 64개의 채널을 멀티 헤드로 사용,
32/16/8 해상도에서 어텐션
업 다운 샘플링을 위한 BigGAN 잔차블록
잔차 블록에 타임 스텝 및 클래스 임베딩을 주입하기 위한 adaptive group normalization을 쓴다고함

----------------------------------------------------------------------------

4. 분류기 지침(Classifier Guidance)

첫 문단 요약 - 구조 말고 조건적 이미지 합성에는 클래스 레이블을 사용하는 것도 중요하다

두 번째 문단
※ ∇는 나블라, 델, 다변수 함수 or 벡터 미분용 연산자 https://daewonjang.gitbooks.io/vector-calculus/content/chapter2.html

정규화 레이어에 클래스 정보가 이미 통합되었으므로(Sec 3.1)

뷴류기 p(y|x)를 활용하여 diffusion sampling process를 개선한다

4 sec의 클래시파이어 p 어쩌고를 활용한다~ 부터 다시 시작
노이즈 샘플링 할 때 뭔가 신묘한 기법을 사용하는듯
't 시점에서 label을 고려한다'가 뭔지도 알아보자

디퓨전 생성기를 개선하기 위해 classifier p(y|x)를 활용한다 - 이 문장은 잡음뜨기 할 때? 혹은 다른 과정에서 분류기의 가능도(가중치가 맞나?)를 활용한다는 뜻인가?

분류기의 기울기를 사용해 사전 학습된 확산 모델을 조건화한다 - 이건 또 뭔소린가

노이즈가 많은 이미지 x_t에서 classifier p_ɸ(y|x_t, t)를 학습 시킬 수 있다
?????
p(y|x)가 분류기 함수라면, x는 텐서고(여기서는 이미지) y는 클래스인가?
그렇다면 p_ɸ(y|x_t, t)는 잡음 단계와 잡음낀 이미지를 가지고 클래스를 추측하는 분류기인가?
논문에서는 이것이 학습 가능하다고 한다

학습 하고 분류기의 기울기를 가지고
학습한 라벨 y를 향해 확산 샘플링 과정을 'guide'한다
∇x_t log p_ɸ(y|x_t, t)

나블라가, 기울기가 뭔데 씹덕아 -> https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%9A%B8%EA%B8%B0_(%EB%B2%A1%ED%84%B0)
∇f 에서 f자리에 x_t가 왔으므로 텐서를 통째로 편미분하는듯?
f(x, y, z) = 2x + 3y^2 - sin(z)의 기울기는
∇f = (∂f/ax, ∂f/ay, ∂f/az) = (2, 6y, - cos z)
∂f/ax는 x에 대한 f의 편미분
x_t 텐서 각각의 값에 대한 x_t의 편미분을 한 값인것이 기울기
그럼 log p_ɸ(y|x_t, t)는 대체 왜 잡음 이미지 분류값에 로그를 씌웠나?
그리고 앞의 나블라 연산자와는 무슨상관인가? x_t는 뒤의 로그값과 통째로 계산하는가? 따로 계산해서 곱하는가?
-> 코드를 보고 알아낼것

classifier를 이용한 조건적 샘플링 프로세스 도출하는 2가지 방법을검토하고
샘플 품질 향상을 위해 classifier를 사용하는 방법을 설명한다고 함
추가로 논문에서 표기를 p_ɸ(y|x_t, t) = p_ɸ(y|x_t)와 ε_θ(x_t, t) = ε_θ(x_t)로 간결하게 한다고함
각각 noisy_image2class/noisy_image2noise로 추정함

-----
4.1 조건적 역방향 잡음 과정
p_θ(x_t|x_t+1)은 p_θ(x_t-1|x_t) 역방향 분포를 근사화하여 잡음 추가를 되돌리는 신경망이다 그리고 여기서 시작한다
이를 조건화한다는게 뭔소린가?

p_θ, ɸ로 시작하는걸로 보아 변수가 2개인듯
https://datascienceschool.net/02%20mathematics/07.04%20%EB%8B%A4%EB%B3%80%EC%88%98%20%ED%99%95%EB%A5%A0%EB%B3%80%EC%88%98.html
다변수 확률변수로 넘어간듯?

전체 식은
p_θ, ɸ(x_t|x_t+1, y) = Z * p_θ(x_t-1|x_t) * p_ɸ(y|x_t)
Z는 정규화 상수라고 하며,
클래스와 잡음낀 이미지를 매개변수로 잡음덜낀 이미지를 만들어낸다
Z와 역방향 과정과 잡음낀이미지로부터의 클래스추정(의 기울기?)의 곱을 이용하여

p_θ(x_t|x_t+1) = N(μ, Σ) -> 평균과 표준편차(의 합? 왜 시그마?)을 가지고 뭔가 한다는 뜻인가? 평균과 표준편차가 맞기는 한가?
로그는 또 왜 박는가?
log p_θ(x_t|x_t+1) = -1/2 (x_t-μ)^T Σ^-1 (x_t - μ) + C -> 이건 대체 뭔소리인가? ddpm이나 다른 확산 스케줄 논문에서 원본을 찾아보자
일단 형식 자체는 텐서연산인데 왜 로그가 붙어있는지는 몰?루

우리는 log_ɸ p(y|x_t)가 ∑^-1에 비해 낮은 곡률을 가지고 있다고 가정할 수 있습니다.
이 가정은 |∑| → 0인 무한 diffusion 단계의 한계에서 합리적입니다.
이 경우 x_t = μ 주변의 테일러 확장을
-> ????????? 이게 다 무슨 소리야, 수알못에서 언젠가 벗어나자
--> μ가 대체 뭔데? N(xt−1; µθ(xt, t), Σθ(xt, t)) 에서 앞서 뮤를 언급했었는데 뭘 지칭하는지 모르겠음 x_t = μ 같은 식이 나오는걸 보니 평균 픽셀 값인가?

x_t = μ 주변의 테일러 전개하면(해석학적인 능력을 기르자... 뭔소리야)
log p_ɸ(y|x_t) ≈ (log p_ɸ(y|x_t) | x_t=μ) + ((x_t - μ)∇x_t log p_ɸ(y|x_t)|x_t = μ)
= (x_t - ㅎ)g + C_1
여기서 g = ∇x_t log p_ɸ(y|x_t)|x_t = μ)와 C_1은 상수라고 한다

log(p_θ(x_t|x_t+1)p_ɸ(y|x_t)) = -1/2 (x_t-μ)^T Σ^-1 (x_t - μ) + (x_t - μ)g + C_2 ※ 이거 위 두 식을 로그 안에서 곱했으므로 로그 밖에서는 더해지나? log a + log b = log (a*b)이므로?
                              = -1/2 (x_t-μ-Σg)^T * Σ^-1((x_t-μ-Σg) + 1/2 g^T Σg + C_2 -> 여기서부터 뭔소린지 1도모르겠음
                              = -1/2 (x_t-μ-Σg)^T * Σ^-1((x_t-μ-Σg) + C_3
                              = log p(z) + C_4, z~N(μ + Σg, Σ)
C_4는 정규화 계수 Z에 해당하므로 안전하게 무시가능??
조건적 transition 연산자는 무조건적 transition 연산자와 비슷하지만 평균이 Σg만큼 이동된 정규분포에 근사될 수 있음
알고리즘 파트에 요약본 있음
s는 그래디언트 스케일링 팩터

-----
4.2 DDIM을 위한 조건적 샘플링
DDIM 같은 결정론적 샘플링 방법에는 4.1과 같은 확률적 확산 샘플링 과정에 쓰는 방식을 쓸 수 없다고한다

4.1의 방법이 안되니까?(애초에 뭔지도 잘 모르겠음)
확산 모델에 점수 맞춤(score amtching)간에 연결을 활용하는 song et al의 score기반 조건화 트릭을 사용한다고한다
https://arxiv.org/abs/2011.13456 (해당 논문이다)

하여튼간에, 노이즈 예측 모델 ε_θ(x_t)가 있다면 score 함수를 도출하는데 쓸  수 있다고 한다
∇x_t log p_θ(x_t) = - (1/sqrt(1-a_t_bar)) * ε_θ(x_t)
이 것을 p(x_t)p(y|x_t)에 대한 score 함수로 대체할 수 있다고 한다

∇x_t log(p_θ(x_t)p_ɸ(y|x_t)) = ∇x_t log(p_θ(x_t)) + ∇x_t log(p_ɸ(y|x_t))
                             = - (1/sqrt(1-a_t_bar)) * ε_θ(x_t) + ∇x_t log(p_ɸ(y|x_t))

공동 분포의 score에 해당하는 새로운 엡실론 예측 ε_hat(x_t)를 정의할 수 있다
(:= 는 왼쪽을 오른쪽으로 def 즉 정의 한다는 뜻)
ε_hat(x_t) := ε_θ(x_t) - sqrt(1-a_t_bar) * ∇x_t log(p_ɸ(y|x_t))

대체 무슨 맥락일까? ∇x_t log(p_θ(x_t)p_ɸ(y|x_t))는 클래스 guide된 역방향 확산 프로세스의 로그의 그레디언트인가?
그렇다면 -sqrt(1-a_t_bar)를 곱해서 정의한 epsilon_hat(x_t)는 대체 뭔가? 수정된 잡음 예측인가? 대체 -sqrt값은 왜 곱했나?

algo 2에는 샘플링 알고리즘이 나와있다

-----
분류기 기울기에는 1보다 큰 상수 인자로 스케일링 하는것이 성능에 좋다는것이 실험적으로 알려진듯
원리 거르고, 더 큰 기울기 규모 조정은 분류기의 모드(이게 뭐지? 원문에도 "mode"로 나와있음)에 초점을 더 맞추는데
이건 덜 다양하고 더 높은 샘플을 만든다고함

조건적 확산 모델 p(x|y)를 학습하고 분류기 지침을 동일하게 사용하고 샘플 품질을 향상

이후로는 옵션따라 평가 척도에 관한 내용

----------------------------------------------------------------------------
