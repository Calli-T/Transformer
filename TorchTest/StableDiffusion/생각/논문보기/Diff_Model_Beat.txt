Diffusion Models Beat GANs on Image Synthesis
https://arxiv.org/pdf/2105.05233

초록
현행 SOTA 생성 모델보다 확산 모델이 더 우월한 이미지 견본에 도달할 수 있다

우린 이걸(우월한 이미지 견본) 일련의 절제를 통한 더 나은 구조를 찾는것으로
무조건적인(unconditional) 이미지 합성에 이것(SOTA?)을 달성하였다 -> 뭔소리야

우리는 조건부 이미지 합성을 위해
견본의 질을 분류자 지침
즉 분류기의 기울기를 사용하여
다양성과 견고함을 맞교환하는 간단하고
계산 효율적인 방법을 사용하여
견본의 질을 더욱 향상한다.
-> 뭔가 trade off인걸 잘 조절한듯?

※ FID: Frechet Inception Distance, 생성 영상의 집합과 실제 생성하고자 하는 클래스 데이터 분포간의 거리
가까울 수록 좋은 값, https://m.blog.naver.com/chrhdhkd/222013835684

그 아래는 대충 크기별 IMAGENET 데이터셋에서 FID점수 몇 점, 몇 점 나왔다는 내용과
깃허브 링크

----------------------------------------------------------------------------
1. 소개
몇 년 동안 생성 모델은 사람같은 자연어, 무한한 고품질 이미지 합성과
매우 다양한 사람말 그리고 음악 등을 생성할 수 있는 능력을 얻었다

이 모델들은 텍스트 프롬프트에서 이미지를 생성하거나 표현에서 유용한 특성을 학습하는등 다양하게 사용될 수 있다

이 모델들이 이미 현실적인 이미지와 사운드를 만들어내는데 유용할지라도,
현행 SOTA 모델을 너머의 많은 발전의 방들이 많이 있습니다.(발전할 여지가 많다는 뜻인듯)
그리고 더 나은 생성 모델은 그래픽 디자인, 게임, 음악 작업과 무수한 분야에 광범위한 충격이었을지도 모른다.

생성형 적대 신경망들은 지금 대부분의 이미지 생성 작업의 SOTA를 꽉 쥐고있고
이는 FID, IS, Precision 같은 견본 품질 척도로 계측되었다

그러나 저 척도들 가운데 어느 것들은 다양성을 전부 포착하지는 못한다
그리고 그건 생성형 적대 신경망들이 가능도 기반의 SOTA 모델들보다
다양성(= diversity)을 적게 잡아냈음을 보여왔다

더욱이 생성형 적대 신경망은 대부분 학습하기 어렵고
신경써서 선별된 hyperparamter와 regularizers(정규화하는장치, 정칙자)없이는 자주 붕괴(colllapsing, 기울기 얘기인듯?)해버린다.

생성형 적대 신경망(GAN)이 SOTA를 쥐고있을 때에는
GAN의 약점으로 인해 규모조절(scale)하고 새로운 영역(domains)들에 적용하기 어려웠습니다.

그 결과, 가능도 기반 모델로 GAN과 유사한(원문은 GAN-like)
품질을 달성하는데 많은 작업이 수행되었다.

이 모델들이 GAN보다 많은 더 많은 다양성을 잡아내고 일반적으로 더 쉽게 scale하고 학습하는 동안
시각적 견본 품질 측면에서 여전히 부족했었다

더욱이, VAE(변형 자기 부호화기)를 제외하고는
이 모델들로 샘플링하는것은 GAN보다 벽시계 시간으로 봐도(??? 많이 느리다는 뜻인가?) 느렸습니다

확산 모델은 가능도 기반 모델 종류이며 최근에 고품질 이미지를 생산하는걸 보여줬다
분포 범위나 변화없는 학습 객체, 쉬운 확장성 같은 바람직한 속성을 제공하면서 말이다 -> ???

이 모델들은 신호로부터 잡음을 점진적으로 생성하여 견본을 생성한다
그리고 그것들의 학습 객체는 재가중치화된 변형하한으로 표현될 수 있다 -> ???

(대충 LSUN이나 IMAGENET 등의 생성 데이터셋에서 GAN보다 밀렸으나
고성능 컴퓨터로 성능 개선을 했다는뜻)

upsampling하여 IMAGENET 256x256도 견본뜨기 가능
그러나 FID점수가 여전히 BIG-GAN보다는 별로라고함

GAN모델과의 점수차에 대한 가설 2개 세움
1. GAN모델이 문자그대로 빡세게 탐구되고 세련화되었음
2. GAN은 고품질 견본을 생산함으로 다양성과 견고함을 상충할 수 있음

그러나 전체 분포를 감당하지는 다루지는 못함 -> 이 부분이 확산 모델에 이득을 가져와줄것을 노렸음

먼저는 모델 구조를 개선하고 그 다음엔 다양성과 안정성의 상충의 계획을 고안한다
(대충 GAN을 뛰어넘을거라는뜻)

논문 구성은 섹션 2에서 확산 설명
섹션 3에서 FID를 향상시키는 개선 사항
섹션 4에서는 활용방법
섹션 5에서는

무조건 이미지 합성에는 구조 개선을 통해
조건 이미지 합성에 분류기 지침을 사용함으로
25회 만큼 적게 정방향 (확산 과정)을
BigGAN과 비교할만하게 FID를 유지하는것을 발견하였다 <- 이게 핵심인듯?

??? '조건부'라는 뜻은 조건부 확률을 사용하는 뜻 or 라벨링이 되어있다는 뜻으로 추측

----------------------------------------------------------------------------
2. 배경
확산 모델 요약 해줌, 수학적 디테일은 첨부 B를 읽어볼것...이라고함