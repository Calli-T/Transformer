자연어 처리의 문제점
모호성: 단어와 구가 사용 맥락에 따른 여러 의미를 갖게 되어 모호함
가변성: 사투리, 강세, 신조어, 작문 스타일로 인해 가변적
구조: 문장이나 구의 의미를 이해할 때 구문을 파악하여 의미를 해석한다.
알고리즘은 문장의 구조와 문법적 요소를 이해하여 의미를 추론하거나 분석할 수 있어야 한다.

이런 문제를 이해하고 구분할 수 있는 모델을 만드려면
말뭉치를 일정한 단위의 토큰으로 나눠야 한다

말뭉치는 말그대로 자연어 텍스트 데이터셋이고
토큰은 개별 단어나 문장 부호 등 말뭉치를 학습용으로 나눈 작은 단위이다
토큰화는 토큰으로 나누는 과정

토크나이저 구축방법의 종류
공백분할: 텍스트를 공백단위로 분리해 개별 단어로 토큰화
정규표현식: 정규 표현식으로 특정 패턴을 식별해 텍스트 분할
어휘 사전 적용: 사전에 정의된 단어 집합을 토큰으로 사용
머신러닝 활용: 데이터셋을 기반으로 토큰화하는 방법을 학습한 머신러닝을 적용

어휘 사전의 경우 사전에 정의된 단어를 활용해 토크나이저를 구축하지만
OOV(Out of Vocab)이라 하여 없는 단어가 존재할 수 있으며 이를 고려해야한다.

232p
큰 어휘 사전을 구축하면 학습 비용이 증대하고 차원의 저주에 빠질 수도 있다.
차원의 저주란? 학습 데이터의 차원이 증가할 수록 학습에 필요한 데이터가 증가하거나 모델의 성능이 저하되는 현상을 의미한다.

단어의 수가 많아질수록 벡터값이 거의 0을 가지는 희소 데이터로 표현된다
희소 데이터의 표현방법은 사전 단어 출현 빈도만 고려하므로 문장내 토큰간의 순서 관계를 잘 표현하지 못한다.

----------------------------------------
단어 토큰화: 띄워쓰기나 문장부호로 의미있는 단어를 구분하여 토큰화
글자 토큰화: 글자 단위로 토큰화
자모 토큰화: 한글 토큰화를 자소 단위로 분리, 완성형에서 조합형으로

글자 토큰화는 작은 단어 사전을 구축하고 이는
학습 때 자원을 아끼고
전체 말뭉치에서 각 단어를 더 자주 학습하는 장점이 있다고한다...

(자모 토큰화에서)개별 토큰은 의미가 없으므로 자연어 모델이 각 토큰의 의미를 조합해 결과를 도출해야한다.
토큰 조합 방식해 문장 생성이나 개체명 인식을 구현할 경우. 다의어나 동음이의어가 많은 도메인에서 구별이 어려워진다.
또한 모델 입력 시퀀스의 길이가 길어지면 연산량이 증가하는 단점이 있다.
※개체명 인식: 자연어 내에서 사전에 정의된 이름을 가진 개체를 인식하고 추출하는 자연어처리의 한 분야
----------------------------------------
형태소 토큰화: 텍스트를 의미가 있는 최소 단위로 나누는 토큰화 방식

교착어는 접사를 붙여 의미를 완성해나가는 언어이며
한국어는 교착어이다
교착어는 형태소 토큰화를 중요하게 생각한다

형태소는 또다시 스스로 의미를 지니는 자렵 형태소와 그렇지 않은 의존 형태소로 나뉜다

237p
형태소 어휘 사전: 자연어 처리에서 사용되는 단어의 집합 중에서도 각 단어의 형태소 정보를 포함하는 사전
이를 통해 문맥을 고려할 수 있기에 더욱 정확한 분석이 가능해진다.

238p
KoNLPy/NLTK/spaCy 라이브러리를 활용해 형태소 단위의 토큰화가 가능하다

241p
Okt보단 Kkma가 좀 더 자세하게 분리하는듯

242p
NLPK의 품사 태깅에는 Punkt나 Averaged Perception Tagger