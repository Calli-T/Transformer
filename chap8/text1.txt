454p
※ 이미지 분류: 객체나 장면 같은 요소를 인식하고 분류하는 알고리즘

지도학습인 이유는, 이미지/이미지에 해당하는 클래스로 데이터셋을 구성
컴퓨터 비전 분야에서 가장 자주 사용되는 알고리즘
사용자가 입력한 이미지를 사전에 정의한 클래스중 가장 유사한 클래스로 판별하는 작업

단일 클래스 분류: 하나의 대표 클래스에 대해 참 거짓으로 분류
다중 클래스 분류: 하나의 데이터 포인트를 여러 개의 상호 배타적인 클래스 중 하나로 분류하는 머신러닝 과정이다.
다중 레이블 분류: 입력에 대해 여러 개의 독립적인 이진 레이블을 예측하는 문제, 다중 클래스 분류와 달리 여러 클래스에 동시에 속하는것 가능

서포트 벡터 머신/K-최근접 이웃 알고리즘/의사결정 나무/인공 신경망/CNN이 모두 해당 알고리즘이나,
책에서는 CNN만 다룬다

456p
여타 CNN 모델 설명 - 무던히 아는 내용이니 넘어가면될듯
AlexNet은 LeNet-5와 비슷
입력/합성곱/최댓값 풀링/완전연결/출력으로 되어있다

LeNet-5에서 AlexNet으로 갈 때
주요 차이는 활성화함수가 Sigmoid->ReLU로 바뀐것과
Mean pooling -> Max pooling으로 바뀐것과
드롭아웃을 활용함에 있다

각각 기울기 소실 문제와/최댓값의 분포 안정화와/과적합 문제를 개선하였다

458p
torchinfo 라이브러리는 모델 구조를 확인하는 라이브러리이다
모델에 사용된 계층과, 입/출력 형태, 전체 매개변수의 수를 확인하는 기능을 제공한다
information = torchinfo.summary(
    model,
    input_data
)
해당 함수를 사용하면 모델과 입력 데이터를 전달했을 때
각 계층의 출력 형태와 매개변수의 수를 확인할 수 있다

정보 중에서 acc@1와 acc@5는 상위 n개 레이블에 대한 예측 정확도를 의미한다.
GFLOPS는 기가플롭스로 1초당 수행할 수 있는 부동 소수점 산술 연산의 수

463p
torchvision.transforms.Normalize함수는
각각 R채널/G채널/B채널의 평균/표준편차를 입력으로 받는다
(사용된 값은 imagenet 데이터셋의 평균과 표준 편차)

466p
GoogLeNet은 Inception을 사용함
VGG-16과 AlexNet은 유사함 사용된 층이 같지만 다만 계층이 더 많음
VGG-16는 3x3 커널 사용함, 11x11보다 작은걸 써서 전역 특징보다는 지역 특징을 잘 잡아냄
3x3필터를 여러번 사용하며 7x7필터를 대체함

더 작은 필터의 크기를 여러번 적용하면 모델 매개변수의 수가 감수 & 활성화 함수의 증가로 비선형성 증가 -> (더 복잡한 패턴을 잘 인식)

실습은 1000개/100개 2200개의 데이터셋으로 진행함

478p

ResNet은 깊은 신경망 구조로 인한 기울기 소멸 문제를 해결하기위해
잔차연결/항등사상(Identity Mapping)/잔차블록(Residual Block)등을 사용한다

기본 구조는 입력/합성곱/배치정규화/활성화함수/잔차블록/평균값풀링/완전연결/출력 층이 있다
34,50,101,152 계층짜리 모델이 개발된적이 있다

합성곱을 거친값 + 합성곱을 거치지 않은 원래값 = 다음 합성곱층의 입력
※ 실제 모델에서는 층 2개 단위로 거친값, 거치지 않은값을 합쳐서 보낸듯

일반적인 CNN은 현재 계층에서 정보가 손실되면
다음 계층에서 기울기가 소실되는 문제가 발생함
또한 깊은 모델에서는 기울기 소멸이 발생함
이런 문제를 위 과정 즉 단축 연결을 통해 해결

※ 단축연결(Shortcut connection): 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조
(=Residual connection =Skip Connection)

480p
깊은 구조의 모델
장점: 더 많은 특징벡터 계산은 계층마다 더 세밀한 지역 특징과 전역 특징의 구별로, 이는 다시 모델의 표현력 향상과 복잡한 문제 해결로 이어진다
단점: 기울기가 소실된다

481p
※ 잔차학습: 모델이 입력과 출력 사이의 차이만 학습하게 하는 방법

https://channelai.tistory.com/2
하나의 직관에서부터 나온 아이디어 - 더 깊은 신경망이 덜 깊은 신경망 '이상'의 성능을 보장하는
방법은 덜 깊은 신경망을 그대로 복사하고
추가 계층은 전부 항등 사상(Identity mapping)으로 초기화된 계층으로 대체(??? 행렬 I와 같은것인가?)
직관에 따르면, 모델의 결과를 그대로 출력하므로 성능하락이 없을것이지만, 기울기 저하 문제가 발생했다.
NN은 identity mapping을 학습하는것을 어려워한다는 가설을 세우고
모델이 입력과 출력의 차이만 학습하게 하는 방법을 세웠다 -> 이는 성능향상을 이끌어 내었다.(경험적으로 알게된 사실)

482p
출력 H(x)보다는 학습한 함수에 input을 더한 F(x) + x를 더해 그걸 학습하는 아이디어 사용
잔여효과인 F(x)만 학습한다

동일한 차원간에 잔차연결은
y=F(x, {W_i}) + x이며
동일하지 않은 차원간에 잔차연결의 수식은
y = F(x, {W_i}) + W_s*x이다

x: 이전 계층의 출력값
W_i: 현재 계층
F: 입력값 x가 여러 계층을 통과한 결괏값
※ F와 x의 차원이 동일하면 덧셈 연산 가능, 같지 않으면 차원을 맞추기위해 x에 W_s 가중치행렬 적용
※ 입력한 차원이 n이고 출력이 n+k라면 W_s는 (n+k)*n이다. 여기 들어오면 n+k 차원 벡터를 생성가능, 이를통해 다른 차원에도 입력값이 보존

483p
??? ??? ??? (차원수를 줄이는 과정을 좀 더 자세하게 알아보자)
채널수에 관한 정보는
https://velog.io/@ym980118/%EB%94%A5%EB%9F%AC%EB%8B%9D-%ED%95%84%ED%84%B0-%EA%B0%9C%EC%88%98-%EC%B1%84%EB%84%90-%EA%B0%9C%EC%88%98-%ED%97%B7%EA%B0%88%EB%A6%AC%EB%8A%94-%EA%B1%B0-%EC%A0%95%EB%A6%AC
필터는 여러개의 커널의 묶음/필터 하나 당 한 개의 feature map을 출력

병목블록은 깊은 모델 구조를 유지하면서 연산량을 줄일 수 있다.
1x1합성곱 계층으로 입력 특징 맵의 차원수를 줄이고 ->
3x3 합성곱 계층을 통해 필터 적용 ->
다시 1x1 합성곱 계층으로 특징 맵의 차원 수를 증가


딥한 원리는 https://coding-yoon.tistory.com/116
정보손실과 연산량의 trade-off를 잡아줘야한다고 한다

485p
레즈넷은 기본적으로 블록이 하나의 스테이지 안에서 여러번 반복되는 구조이다.

ResNet-50부터는 깊어서 병목 블록을 써야한다고 한다.
ResNet-18과 ResNet-34의 기본 블록은 3x3 Conv, Batch Norm, ReLU의 두 번 반복으로 이루져있다.

486p설명부터 다시시작