454p
※ 이미지 분류: 객체나 장면 같은 요소를 인식하고 분류하는 알고리즘

지도학습인 이유는, 이미지/이미지에 해당하는 클래스로 데이터셋을 구성
컴퓨터 비전 분야에서 가장 자주 사용되는 알고리즘
사용자가 입력한 이미지를 사전에 정의한 클래스중 가장 유사한 클래스로 판별하는 작업

단일 클래스 분류: 하나의 대표 클래스에 대해 참 거짓으로 분류
다중 클래스 분류: 하나의 데이터 포인트를 여러 개의 상호 배타적인 클래스 중 하나로 분류하는 머신러닝 과정이다.
다중 레이블 분류: 입력에 대해 여러 개의 독립적인 이진 레이블을 예측하는 문제, 다중 클래스 분류와 달리 여러 클래스에 동시에 속하는것 가능

서포트 벡터 머신/K-최근접 이웃 알고리즘/의사결정 나무/인공 신경망/CNN이 모두 해당 알고리즘이나,
책에서는 CNN만 다룬다

456p
여타 CNN 모델 설명 - 무던히 아는 내용이니 넘어가면될듯
AlexNet은 LeNet-5와 비슷
입력/합성곱/최댓값 풀링/완전연결/출력으로 되어있다

LeNet-5에서 AlexNet으로 갈 때
주요 차이는 활성화함수가 Sigmoid->ReLU로 바뀐것과
Mean pooling -> Max pooling으로 바뀐것과
드롭아웃을 활용함에 있다

각각 기울기 소실 문제와/최댓값의 분포 안정화와/과적합 문제를 개선하였다

458p
torchinfo 라이브러리는 모델 구조를 확인하는 라이브러리이다
모델에 사용된 계층과, 입/출력 형태, 전체 매개변수의 수를 확인하는 기능을 제공한다
information = torchinfo.summary(
    model,
    input_data
)
해당 함수를 사용하면 모델과 입력 데이터를 전달했을 때
각 계층의 출력 형태와 매개변수의 수를 확인할 수 있다

정보 중에서 acc@1와 acc@5는 상위 n개 레이블에 대한 예측 정확도를 의미한다.
GFLOPS는 기가플롭스로 1초당 수행할 수 있는 부동 소수점 산술 연산의 수

463p
torchvision.transforms.Normalize함수는
각각 R채널/G채널/B채널의 평균/표준편차를 입력으로 받는다
(사용된 값은 imagenet 데이터셋의 평균과 표준 편차)

466p
GoogLeNet은 Inception을 사용함
VGG-16과 AlexNet은 유사함 사용된 층이 같지만 다만 계층이 더 많음
VGG-16는 3x3 커널 사용함, 11x11보다 작은걸 써서 전역 특징보다는 지역 특징을 잘 잡아냄
3x3필터를 여러번 사용하며 7x7필터를 대체함

더 작은 필터의 크기를 여러번 적용하면 모델 매개변수의 수가 감수 & 활성화 함수의 증가로 비선형성 증가 -> (더 복잡한 패턴을 잘 인식)