336p
합성곱 신경망은 입력 데이터의 지역적 특징을 추출하는데 특화됨 - 이를 위해 합성곱 연산을 사용
합성곱 연산은 이미지의 특정 영역에서 입력값의 분포나 변화량을 계산해 출력 노드를 생성 - 지역 특징을 효과적으로 추출
이미지 데이터는 고정된 프레임 안에 객체들의 위치와 형태가 자유분방 - 여러 지역 특징을 조합 - 전역 특징을 파악가능

순환신경망의 연산 순서 제약으로 병렬처리가 어려움,
입력 데이터의 길이가 길면 처리속도가 느려짐, 많은 가중치는 학습이 어려움 -> 깊은 신경망 구성이 어려움
==> 합성곱 신경망을 사용하여 개선
입력 데이터 길이와 무관하게 병렬 처리가능, 가중치 수가 줄어들어서 깊은 신경망 가능

337p
입력 데이터의 모든 위치에서 동일한 필터 사용
-> 모델 매개변수 공유
-> 매개변수 수가 감소해 과대적합 방지
같은 필터를 stride만큼 움직이면서 쓰니까? 나오는 소리로 추측함

필터를 입력 데이터와 겹치면서, 겹쳐지는 위치와 곱해서 그 합을 추출하는 식

338p
패딩 - 패스
간격 - 패스

340p
채널
입력 데이터와 필터 간의 연산은 채널에서 수행됨
입력 데이터와 필터가 3차원으로 구성됐을 경우, 같은 위치의 값들이 서로 연산되도록 한다.
특징 맵의 개수는 채널의 개수만큼 존재, ex) RGB의 경우 특징 맵 3개
채널 개수는 모델의 구조나 목적에 따라 달라진다 - 많으면 모델의 표현력 증가/리소스 증가 및 과대적합위험

---
팽창(Dilation): 합성곱 연산의 수행에서
필터와 입력 데이터 사이에 간격을 둠으로써,
입력 데이터에 더 넓은 범위를 고려하는 기법

간격 즉 stride와 다르게 필터가 내부가 퍼진다
dilation은 1이 일반적이며 2의 경우 3x3 필터가 5x5데이터의 9개 데이터를 합성곱하는 방식
필터 내부에 간격을 띄우는 식이다

간격을 넓히면 인접 픽셀값을 고려하지 않고,
공간적인 정보가 보존되지 않아
특징 추출의 효과가 떨어질 수 있고/
매개변수를 줄여 리소스 감소, 각 픽셀의 영향 강화, 더 넓은 영역을 고려하여 깊고 복잡한 모델가능
-> 이거 쓰긴하는가 모르겠다

토치 CNN 사용법
conv = torch.nn.Conv2d(
    in_channels, # 입력 데이터 채널(차원) 크기,
    out_channels, # 출력 데이터 채널(차원) 크기,
    kernel_size, # 필터 크기
    stride=1, # 필터 이동 간격
    padding, # 패딩
    dilation=1, # 팽창
    groups=1, # 입력층의 그룹개수, 2이상이면 더 작은 그룹이라고한다???
    bias=True, # 편향 포함 여부
    padding_mode="zeros" # 패딩 모드, zero는 영패딩, reflect는 가장자리 input을 패딩에 반전해서 복자, replicate 가장자리 값 복제
)

딴건 모르겠고 그룹은 뭔소린지 나중에 알아보자
343p부터 시작